{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from numpy import asarray\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
    "\n",
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer  \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# DATASET\n",
    "DATASET_COLUMNS = ['Id', 'Review', 'Sentiment']\n",
    "# Define a dictionary to map sentiment values to category names\n",
    "senti_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
    "senti_categories = list(senti_labels.values())\n",
    "NUM_of_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/s3985113/Thesis_Jupyter_Final/src/\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.dirname(os.path.abspath('mc_lstm.ipynb'))\n",
    "data_path = os.path.join(script_dir, 'Thesis_Jupyter_Final/src/')\n",
    "os.getcwd()\n",
    "print(data_path)\n",
    "\n",
    "input_folder_path = os.path.join(data_path, 'input')\n",
    "processed_folder_path = os.path.join(data_path, 'input/processed')\n",
    "results_folder_path = \"results\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(results_folder_path):\n",
    "    os.makedirs(results_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# just checkıng gpu ıs avaılable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.011353   -0.017666    0.36414    ...  0.067372   -0.02874\n",
      "  -0.43744001]]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(input_folder_path, \"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(input_folder_path, \"val.csv\"))\n",
    "test = pd.read_csv(os.path.join(input_folder_path, \"test.csv\"))\n",
    "\n",
    "x_train = train['x']\n",
    "y_train = train['y']\n",
    "x_val = val['x']\n",
    "y_val = val['y']\n",
    "x_test = test['x']\n",
    "y_test = test['y']\n",
    "\n",
    "x_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_x.npy\"))\n",
    "y_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_y.npy\"))\n",
    "x_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_x.npy\"))\n",
    "y_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_y.npy\"))\n",
    "x_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_x.npy\"))\n",
    "y_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_y.npy\"))\n",
    "\n",
    "w2v_embedding_vectors = np.load(os.path.join(processed_folder_path, \"embedding_matrix.npy\"))\n",
    "print(w2v_embedding_vectors)\n",
    "\n",
    "%store -r embedding_vocab_size\n",
    "%store -r EMBEDDING_DIM\n",
    "%store -r max_seq_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(score):\n",
    "    acc =  score[1]\n",
    "    loss = score[0]\n",
    "\n",
    "    print(f\"Accuracy: {acc:.2%}\")\n",
    "    print(f\"Loss: {loss:.2f}\")\n",
    "    \n",
    "    return acc, loss\n",
    "\n",
    "def calculate_classification_report(y, y_pred, labels):\n",
    "    report = classification_report(y, y_pred, labels=labels)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
    "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=labels)\n",
    "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, model_name, x_encoded, y_encoded, y=None, only_metrics=True):    \n",
    "    y_pred_prob = model.predict(x_encoded)\n",
    "\n",
    "    print(f\"*{model_name}\")\n",
    "    \n",
    "    score = model.evaluate(x_encoded, y_encoded, verbose=0)\n",
    "    calculate_metrics(score)\n",
    "    \n",
    "    senti_labels = ['negative', 'neutral', 'positive'] #TODO: to constants\n",
    "    \n",
    "    if not only_metrics:\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1) + 1\n",
    "        calculate_classification_report(y, y_pred, labels=senti_labels)\n",
    "        plot_confusion_matrix(y, y_pred, labels=senti_labels)\n",
    "    \n",
    "    print()\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
    "    for i, label in enumerate(y):\n",
    "        y_encoded[i, label - 1] = 1\n",
    "\n",
    "    return y_encoded\n",
    "\n",
    "def plot_roc_curve(prob_test_vec, y_test, labels):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    labels = labels\n",
    "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
    "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_test[:, senti],\n",
    "            prob_test_vec[:, senti],\n",
    "            name=f\"ROC curve for {labels[senti]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "        )\n",
    "    \n",
    "def calculate_OvR_roc_auc_score(model, x, y, x_test, y_test, labels): #average??\n",
    "    #y = one_hot_encode(y)\n",
    "    #y_test = one_hot_encode(y_test)\n",
    "\n",
    "    ovr_model = OneVsRestClassifier(model).fit(x, y)\n",
    "    prob_test_vec = ovr_model.predict_proba(x_test)\n",
    "    \n",
    "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
    "    for _ in range(NUM_of_CLASSES):\n",
    "        fpr.append(0)\n",
    "        tpr.append(0)\n",
    "        thresholds.append(0)\n",
    "        auc_score.append(0)\n",
    "    \n",
    "    for i in range(NUM_of_CLASSES):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
    "        auc_score[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    print(f\"AUC score: {auc_score}\")\n",
    "    averaged_auc_score = (sum(auc_score) / NUM_of_CLASSES)\n",
    "    print(f\"Averaged AUC score: {averaged_auc_score:.2f}\")\n",
    "    \n",
    "    plot_roc_curve(prob_test_vec, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_development(history):\n",
    "    acc =  history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_classes = 3\n",
    "batch_size= 16\n",
    "epochs=30\n",
    "\n",
    "num_lstm_layersA = Integer(low=1, high=3, name='num_lstm_layersA')\n",
    "num_lstm_layersB = Integer(low=1, high=3, name='num_lstm_layersB')\n",
    "num_lstm_unitsA = Categorical([32, 64, 128], name='num_lstm_unitsA') \n",
    "num_lstm_unitsB = Categorical([32, 64, 128], name='num_lstm_unitsB') \n",
    "#learning_rate = Categorical([1e-2], name='learning_rate')\n",
    "#adam_decay = Categorical([1e-6, 1e-4, 1e-2], name=\"adam_decay\")\n",
    "\n",
    "search_space = [\n",
    "            num_lstm_layersA,\n",
    "            num_lstm_layersB,\n",
    "            num_lstm_unitsA,\n",
    "            num_lstm_unitsB,\n",
    "            ]\n",
    "\n",
    "# Specify one or more initial points for the search of optimal parameter\n",
    "default_params = [1, \n",
    "                  1, \n",
    "                  32,\n",
    "                  32, \n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_multi_channel_lstm_model(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
    "    # Vocabulary-based embedding layer\n",
    "    inputsA = Input(shape=(max_seq_length,), name=\"input regular embeddings\")\n",
    "    # Word2Vec embedding layer\n",
    "    inputsB = Input(shape=(max_seq_length,), name=\"input word2vec embeddings\")\n",
    "    \n",
    "    # Define an embedding layer for each input\n",
    "    embeddingsA = Embedding(embedding_vocab_size, EMBEDDING_DIM, input_length=max_seq_length, name=\"embeddingsA\")(inputsA)\n",
    "    embeddingsB = Embedding(embedding_vocab_size, EMBEDDING_DIM, input_length=max_seq_length, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
    "    \n",
    "    # Pass both embeddings through their own LSTM layers\n",
    "    lstm_layersA = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_1')(embeddingsA)\n",
    "    lstm_layersA = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_2')(lstm_layersA)\n",
    "\n",
    "    lstm_layersB = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_1')(embeddingsB)\n",
    "    lstm_layersB = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_2')(lstm_layersB)\n",
    "    \n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
    "\n",
    "    # Additional Dense layer for dimensionality reduction \n",
    "    #dense_layer = Dense(16, activation='relu', name=\"dense_layer\")(merged)\n",
    "\n",
    "    # Dense layer for the merged inputs & output Layer\n",
    "    outputs = Dense(num_output_classes, activation='softmax', name=\"output\")(merged)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    #adam = Adam(learning_rate=learning_rate, decay=adam_decay)\n",
    "    model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=search_space)\n",
    "def multi_objective_function(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
    "\n",
    "    model = define_multi_channel_lstm_model(num_lstm_layersA=num_lstm_layersA,\n",
    "                                            num_lstm_layersB=num_lstm_layersB,\n",
    "                                            num_lstm_unitsA=num_lstm_unitsA,\n",
    "                                            num_lstm_unitsB=num_lstm_unitsB,\n",
    "                                            )\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit([x_train_encoded, x_train_encoded],\n",
    "                        y_train_encoded,\n",
    "                        validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
    "                        epochs=epochs, # TODO\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=2\n",
    "                        )\n",
    "    #return the validation accuracy for the last epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    loss = history.history['val_loss'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Loss: {loss:.2}\\n\")\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    \n",
    "    # the optimizer aims for the lowest score, so we return our negative accuracy\n",
    "    return -accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer layer_lstmA_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer layer_lstmA_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer layer_lstmB_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer layer_lstmB_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input regular embeddings (Inpu  [(None, 561)]       0           []                               \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " input word2vec embeddings (Inp  [(None, 561)]       0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " embeddingsA (Embedding)        (None, 561, 100)     2492100     ['input regular embeddings[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " embeddingsB (Embedding)        (None, 561, 100)     2492100     ['input word2vec embeddings[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_lstmA_1 (LSTM)           (None, 561, 64)      42240       ['embeddingsA[0][0]']            \n",
      "                                                                                                  \n",
      " layer_lstmB_1 (LSTM)           (None, 561, 64)      42240       ['embeddingsB[0][0]']            \n",
      "                                                                                                  \n",
      " layer_lstmA_2 (LSTM)           (None, 32)           12416       ['layer_lstmA_1[0][0]']          \n",
      "                                                                                                  \n",
      " layer_lstmB_2 (LSTM)           (None, 32)           12416       ['layer_lstmB_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64)           0           ['layer_lstmA_2[0][0]',          \n",
      "                                                                  'layer_lstmB_2[0][0]']          \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 3)            195         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,093,707\n",
      "Trainable params: 2,601,607\n",
      "Non-trainable params: 2,492,100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 15:25:30.674369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.674407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.674428: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.677396: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.677410: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.677418: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.680669: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.680682: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.680689: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.683911: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.683923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.683930: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.687276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.687290: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.687297: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.690329: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.690341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.690348: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.693457: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.693469: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.693476: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.696341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.696353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.696360: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.700103: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.700119: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.700126: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.703005: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.703017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.703024: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.706143: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.706155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.706162: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-06-16 15:25:30.709046: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-16 15:25:30.709058: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-16 15:25:30.709065: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7' defined at (most recent call last):\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3933638/3072496173.py\", line 1, in <module>\n      gbrt_result = gbrt_minimize(func=multi_objective_function,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/gbrt.py\", line 179, in gbrt_minimize\n      return base_minimize(func, dimensions, base_estimator,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/base.py\", line 282, in base_minimize\n      y0 = list(map(func, x0))\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/utils.py\", line 789, in wrapper\n      objective_value = func(**arg_dict)\n    File \"/tmp/ipykernel_3933638/1050917949.py\", line 11, in multi_objective_function\n      history = model.fit([x_train_encoded, x_train_encoded],\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 5142, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 5121, in _step\n      output, new_states = step_function(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 323, in call\n      c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 262, in _compute_carry_and_output\n      + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3 :])\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 2455, in dot\n      out = tf.matmul(x, y)\nNode: 'model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7}}]] [Op:__inference_train_function_35104]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gbrt_result \u001b[39m=\u001b[39m gbrt_minimize(func\u001b[39m=\u001b[39;49mmulti_objective_function,\n\u001b[1;32m      2\u001b[0m                             dimensions\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m      3\u001b[0m                             n_calls\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                             n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                             x0\u001b[39m=\u001b[39;49mdefault_params)\n",
      "File \u001b[0;32m~/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/gbrt.py:179\u001b[0m, in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m base_estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     base_estimator \u001b[39m=\u001b[39m cook_estimator(\u001b[39m\"\u001b[39m\u001b[39mGBRT\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39mrng,\n\u001b[1;32m    178\u001b[0m                                     n_jobs\u001b[39m=\u001b[39mn_jobs)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mreturn\u001b[39;00m base_minimize(func, dimensions, base_estimator,\n\u001b[1;32m    180\u001b[0m                      n_calls\u001b[39m=\u001b[39;49mn_calls, n_points\u001b[39m=\u001b[39;49mn_points,\n\u001b[1;32m    181\u001b[0m                      n_random_starts\u001b[39m=\u001b[39;49mn_random_starts,\n\u001b[1;32m    182\u001b[0m                      n_initial_points\u001b[39m=\u001b[39;49mn_initial_points,\n\u001b[1;32m    183\u001b[0m                      initial_point_generator\u001b[39m=\u001b[39;49minitial_point_generator,\n\u001b[1;32m    184\u001b[0m                      x0\u001b[39m=\u001b[39;49mx0, y0\u001b[39m=\u001b[39;49my0, random_state\u001b[39m=\u001b[39;49mrandom_state, xi\u001b[39m=\u001b[39;49mxi,\n\u001b[1;32m    185\u001b[0m                      kappa\u001b[39m=\u001b[39;49mkappa, acq_func\u001b[39m=\u001b[39;49macq_func, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    186\u001b[0m                      callback\u001b[39m=\u001b[39;49mcallback, acq_optimizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msampling\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    187\u001b[0m                      model_queue_size\u001b[39m=\u001b[39;49mmodel_queue_size)\n",
      "File \u001b[0;32m~/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/base.py:282\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39m# evaluate y0 if only x0 is provided\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m x0 \u001b[39mand\u001b[39;00m y0 \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     y0 \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(func, x0))\n\u001b[1;32m    283\u001b[0m     n_calls \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y0)\n\u001b[1;32m    284\u001b[0m \u001b[39m# record through tell function\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/thesis/lib/python3.10/site-packages/skopt/utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    786\u001b[0m arg_dict \u001b[39m=\u001b[39m {dim\u001b[39m.\u001b[39mname: value \u001b[39mfor\u001b[39;00m dim, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    788\u001b[0m \u001b[39m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m objective_value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marg_dict)\n\u001b[1;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36mmulti_objective_function\u001b[0;34m(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB)\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m define_multi_channel_lstm_model(num_lstm_layersA\u001b[39m=\u001b[39mnum_lstm_layersA,\n\u001b[1;32m      5\u001b[0m                                         num_lstm_layersB\u001b[39m=\u001b[39mnum_lstm_layersB,\n\u001b[1;32m      6\u001b[0m                                         num_lstm_unitsA\u001b[39m=\u001b[39mnum_lstm_unitsA,\n\u001b[1;32m      7\u001b[0m                                         num_lstm_unitsB\u001b[39m=\u001b[39mnum_lstm_unitsB,\n\u001b[1;32m      8\u001b[0m                                         )\n\u001b[1;32m     10\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([x_train_encoded, x_train_encoded],\n\u001b[1;32m     12\u001b[0m                     y_train_encoded,\n\u001b[1;32m     13\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m([x_val_encoded, x_val_encoded], y_val_encoded),\n\u001b[1;32m     14\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs, \u001b[39m# TODO\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     16\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stopping],\n\u001b[1;32m     17\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     18\u001b[0m                     )\n\u001b[1;32m     19\u001b[0m \u001b[39m#return the validation accuracy for the last epoch.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7' defined at (most recent call last):\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3933638/3072496173.py\", line 1, in <module>\n      gbrt_result = gbrt_minimize(func=multi_objective_function,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/gbrt.py\", line 179, in gbrt_minimize\n      return base_minimize(func, dimensions, base_estimator,\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/optimizer/base.py\", line 282, in base_minimize\n      y0 = list(map(func, x0))\n    File \"/home2/s3985113/venv/thesis/lib/python3.10/site-packages/skopt/utils.py\", line 789, in wrapper\n      objective_value = func(**arg_dict)\n    File \"/tmp/ipykernel_3933638/1050917949.py\", line 11, in multi_objective_function\n      history = model.fit([x_train_encoded, x_train_encoded],\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 5142, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 5121, in _step\n      output, new_states = step_function(\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 323, in call\n      c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 262, in _compute_carry_and_output\n      + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3 :])\n    File \"/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/backend.py\", line 2455, in dot\n      out = tf.matmul(x, y)\nNode: 'model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/layer_lstmA_1/while/lstm_cell_6/MatMul_7}}]] [Op:__inference_train_function_35104]"
     ]
    }
   ],
   "source": [
    "gbrt_result = gbrt_minimize(func=multi_objective_function,\n",
    "                            dimensions=search_space,\n",
    "                            n_calls=12,\n",
    "                            n_jobs=-1,\n",
    "                            x0=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO data frame summarizing parameter search\n",
    "gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
    "print(\"Best Hyperparameters:\", gbrt_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_multi_channel_lstm_model(gbrt_best_params['num_lstm_layersA'],\n",
    "                                        gbrt_best_params['num_lstm_layersB'],\n",
    "                                        gbrt_best_params['num_lstm_unitsA'], \n",
    "                                        gbrt_best_params['num_lstm_unitsB'],\n",
    "                                        )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
    "history = model.fit([x_train_encoded, x_train_encoded],\n",
    "                    y_train_encoded,\n",
    "                    validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
    "                    epochs=epochs, # TODO\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=2\n",
    "                    )\n",
    "plot_development(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([x_train_encoded, x_train_encoded], y_train_encoded)\n",
    "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate([x_val_encoded, x_val_encoded], y_val_encoded, verbose=0)\n",
    "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate([x_test_encoded, x_test_encoded], y_test_encoded, verbose=0)\n",
    "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
    "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
    "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
