{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekinfergan/Thesis_Jupyter_Final/blob/main/src/models/mc_lstm-fix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9A-Xt2ne4djh"
      },
      "source": [
        "# Multi-Channel LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2ckCio4nE6",
        "outputId": "070e5578-9f25-40cb-c09f-91f9fa0921e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Thesis_Jupyter_Final'...\n",
            "remote: Enumerating objects: 664, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 664 (delta 24), reused 65 (delta 20), pack-reused 580\u001b[K\n",
            "Receiving objects: 100% (664/664), 125.54 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (342/342), done.\n",
            "Filtering content: 100% (7/7), 158.45 MiB | 51.76 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ekinfergan/Thesis_Jupyter_Final.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm57pwr44ffU",
        "outputId": "89e9e987-f2d0-4fa7-d263-41fc21770f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Thesis_Jupyter_Final\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd Thesis_Jupyter_Final\n",
        "!git pull\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZq9XZCv4yYu",
        "outputId": "770c80e1-b3df-4d15-e8c1-2711a21bd28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-xllscc1g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-xllscc1g\n",
            "  Resolved https://github.com/scikit-optimize/scikit-optimize.git to commit a2369ddbc332d16d8ff173b12404b03fea472492\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize==0.9.0)\n",
            "  Using cached pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.0) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize==0.9.0) (3.1.0)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.0-py2.py3-none-any.whl size=100250 sha256=e1a5b3a5afcd94b806adc4544683c3c63f786e612e999ec9310c54072880ff23\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ab6pgp8/wheels/2f/f0/ed/db529a96372d05bd34f6c3a2fa7c08ef7a8314315ac46e49d7\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PbAXzVr-4djj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from numpy import asarray\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from itertools import cycle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
        "\n",
        "import skopt\n",
        "from skopt import gbrt_minimize, gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OXWMoudx4djk"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W44Yb05Y6N1-",
        "outputId": "b0ba9271-83af-44f6-9ea8-5268983cde23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Checking if gpu available\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r0LwNX3A7CAp"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EynHCpQ04djk",
        "outputId": "da808053-2de4-4ed6-d9ab-15232c799f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Thesis_Jupyter_Final/src/\n"
          ]
        }
      ],
      "source": [
        "script_dir = os.path.dirname(os.path.abspath('mc_lstm-fix.ipynb'))\n",
        "data_path = os.path.join(script_dir, 'Thesis_Jupyter_Final/src/')\n",
        "os.getcwd()\n",
        "print(data_path)\n",
        "\n",
        "input_folder_path = os.path.join(data_path, 'input')\n",
        "processed_folder_path = os.path.join(data_path, 'input/processed')\n",
        "results_folder_path = \"results\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(results_folder_path):\n",
        "    os.makedirs(results_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FVinrA7E6ISQ"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "# Define a dictionary to map sentiment values to category names\n",
        "senti_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
        "senti_categories = list(senti_labels.values())\n",
        "NUM_of_CLASSES = 3\n",
        "\n",
        "VOCAB_SIZE = 12466\n",
        "MAX_SEQ_LEN = 476\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_OUTPUT_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOIpxE654djm",
        "outputId": "5c81e844-9147-4cd7-92da-0de99c6a1619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.011353   -0.017666    0.36414    ...  0.067372   -0.02874\n",
            "  -0.43744001]]\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "train = pd.read_csv(os.path.join(input_folder_path, \"train.csv\"))\n",
        "val = pd.read_csv(os.path.join(input_folder_path, \"val.csv\"))\n",
        "test = pd.read_csv(os.path.join(input_folder_path, \"test.csv\"))\n",
        "\n",
        "x_train = train['x']\n",
        "y_train = train['y']\n",
        "x_val = val['x']\n",
        "y_val = val['y']\n",
        "x_test = test['x']\n",
        "y_test = test['y']\n",
        "\n",
        "x_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_x.npy\"))\n",
        "y_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_y.npy\"))\n",
        "x_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_x.npy\"))\n",
        "y_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_y.npy\"))\n",
        "x_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_x.npy\"))\n",
        "y_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_y.npy\"))\n",
        "\n",
        "w2v_embedding_vectors = np.load(os.path.join(processed_folder_path, \"embedding_matrix.npy\"))\n",
        "print(w2v_embedding_vectors)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rsJ4d-mY4djn"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7hXUlQ8t4djn"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(score):\n",
        "    acc =  score[1]\n",
        "    loss = score[0]\n",
        "\n",
        "    print(f\"Accuracy: {acc:.2%}\")\n",
        "    print(f\"Loss: {loss:.2f}\")\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def calculate_classification_report(y, y_pred, labels):\n",
        "    report = classification_report(y, y_pred, labels=labels)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels):\n",
        "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
        "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=labels)\n",
        "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
        "    plt.title(f'Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, model_name, x_encoded, y_encoded, y=None, only_metrics=True):\n",
        "    y_pred_prob = model.predict(x_encoded)\n",
        "\n",
        "    print(f\"*{model_name}\")\n",
        "\n",
        "    score = model.evaluate(x_encoded, y_encoded, verbose=0)\n",
        "    calculate_metrics(score)\n",
        "\n",
        "    senti_labels = ['negative', 'neutral', 'positive'] #TODO: to constants\n",
        "\n",
        "    if not only_metrics:\n",
        "        y_pred = np.argmax(y_pred_prob, axis=1) + 1\n",
        "        calculate_classification_report(y, y_pred, labels=senti_labels)\n",
        "        plot_confusion_matrix(y, y_pred, labels=senti_labels)\n",
        "\n",
        "    print()\n",
        "\n",
        "def one_hot_encode(y):\n",
        "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
        "    for i, label in enumerate(y):\n",
        "        y_encoded[i, label - 1] = 1\n",
        "\n",
        "    return y_encoded\n",
        "\n",
        "def plot_roc_curve(prob_test_vec, y_test, labels):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    labels = labels\n",
        "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
        "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
        "        RocCurveDisplay.from_predictions(\n",
        "            y_test[:, senti],\n",
        "            prob_test_vec[:, senti],\n",
        "            name=f\"ROC curve for {labels[senti]}\",\n",
        "            color=color,\n",
        "            ax=ax,\n",
        "        )\n",
        "\n",
        "def calculate_OvR_roc_auc_score(model, x, y, x_test, y_test, labels): #average??\n",
        "    #y = one_hot_encode(y)\n",
        "    #y_test = one_hot_encode(y_test)\n",
        "\n",
        "    ovr_model = OneVsRestClassifier(model).fit(x, y)\n",
        "    prob_test_vec = ovr_model.predict_proba(x_test)\n",
        "\n",
        "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
        "    for _ in range(NUM_of_CLASSES):\n",
        "        fpr.append(0)\n",
        "        tpr.append(0)\n",
        "        thresholds.append(0)\n",
        "        auc_score.append(0)\n",
        "\n",
        "    for i in range(NUM_of_CLASSES):\n",
        "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
        "        auc_score[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    print(f\"AUC score: {auc_score}\")\n",
        "    averaged_auc_score = (sum(auc_score) / NUM_of_CLASSES)\n",
        "    print(f\"Averaged AUC score: {averaged_auc_score:.2f}\")\n",
        "\n",
        "    plot_roc_curve(prob_test_vec, y_test, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A-D1Wuxp4djn"
      },
      "outputs": [],
      "source": [
        "def plot_development(history):\n",
        "    acc =  history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title('Training and validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NsSdt6BJ4djn"
      },
      "source": [
        "## Hypterparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wyxIKf-i4djo"
      },
      "outputs": [],
      "source": [
        "batch_size= 16\n",
        "epochs=5\n",
        "\n",
        "num_lstm_layersA = Integer(low=1, high=3, name='num_lstm_layersA')\n",
        "num_lstm_layersB = Integer(low=1, high=3, name='num_lstm_layersB')\n",
        "num_lstm_unitsA = Categorical([32, 64, 128], name='num_lstm_unitsA')\n",
        "num_lstm_unitsB = Categorical([32, 64, 128], name='num_lstm_unitsB')\n",
        "#learning_rate = Categorical([1e-2], name='learning_rate')\n",
        "#adam_decay = Categorical([1e-6, 1e-4, 1e-2], name=\"adam_decay\")\n",
        "\n",
        "search_space = [\n",
        "            num_lstm_layersA,\n",
        "            num_lstm_layersB,\n",
        "            num_lstm_unitsA,\n",
        "            num_lstm_unitsB,\n",
        "            ]\n",
        "\n",
        "# Specify one or more initial points for the search of optimal parameter\n",
        "default_params = [1,\n",
        "                  1,\n",
        "                  32,\n",
        "                  32,\n",
        "                  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fCIaYavA4djo"
      },
      "outputs": [],
      "source": [
        "def define_multi_channel_lstm_model(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "    # Vocabulary-based embedding layer\n",
        "    inputsA = Input(shape=(MAX_SEQ_LEN,), name=\"input regular embeddings\")\n",
        "    # Word2Vec embedding layer\n",
        "    inputsB = Input(shape=(MAX_SEQ_LEN,), name=\"input word2vec embeddings\")\n",
        "\n",
        "    # Define an embedding layer for each input\n",
        "    embeddingsA = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, name=\"embeddingsA\")(inputsA)\n",
        "    embeddingsB = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
        "\n",
        "    # Pass both embeddings through their own LSTM layers\n",
        "    lstm_layersA = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_1')(embeddingsA)\n",
        "    lstm_layersA = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_2')(lstm_layersA)\n",
        "\n",
        "    lstm_layersB = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_1')(embeddingsB)\n",
        "    lstm_layersB = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_2')(lstm_layersB)\n",
        "\n",
        "\n",
        "    # Concatenate the two inputs\n",
        "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
        "\n",
        "    # Additional Dense layer for dimensionality reduction\n",
        "    #dense_layer = Dense(16, activation='relu', name=\"dense_layer\")(merged)\n",
        "\n",
        "    # Dense layer for the merged inputs & output Layer\n",
        "    outputs = Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output\")(merged)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VH3zXV_N4djo"
      },
      "outputs": [],
      "source": [
        "@use_named_args(dimensions=search_space)\n",
        "def multi_objective_function(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "\n",
        "    model = define_multi_channel_lstm_model(num_lstm_layersA=num_lstm_layersA,\n",
        "                                            num_lstm_layersB=num_lstm_layersB,\n",
        "                                            num_lstm_unitsA=num_lstm_unitsA,\n",
        "                                            num_lstm_unitsB=num_lstm_unitsB,\n",
        "                                            )\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                        y_train_encoded,\n",
        "                        validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                        epochs=epochs, # TODO\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=2\n",
        "                        )\n",
        "    # Return the validation accuracy for the last epoch\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "    loss = history.history['val_loss'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Loss: {loss:.2}\\n\")\n",
        "\n",
        "    del model\n",
        "\n",
        "    # Clear the session\n",
        "    K.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    # the optimizer aims for the lowest score, so we return our negative accuracy\n",
        "    return -accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2eR46EJAhRk",
        "outputId": "c3470f38-9cb1-4785-e1bd-28bccd4e1ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jun 16 16:20:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    31W /  70W |   1147MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "21NqrLwz4djp"
      },
      "source": [
        "## Gradient Boosted Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LSzYfcpm4djp",
        "outputId": "981328c4-77fc-4bf3-b46d-4a161459b61d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer layer_lstmA_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer layer_lstmA_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer layer_lstmB_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer layer_lstmB_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input regular embeddings (Inpu  [(None, 561)]       0           []                               \n",
            " tLayer)                                                                                          \n",
            "                                                                                                  \n",
            " input word2vec embeddings (Inp  [(None, 561)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsA (Embedding)        (None, 561, 100)     2492100     ['input regular embeddings[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 561, 100)     2492100     ['input word2vec embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 561, 64)      42240       ['embeddingsA[0][0]']            \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 561, 64)      42240       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " layer_lstmA_2 (LSTM)           (None, 32)           12416       ['layer_lstmA_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmB_2 (LSTM)           (None, 32)           12416       ['layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['layer_lstmA_2[0][0]',          \n",
            "                                                                  'layer_lstmB_2[0][0]']          \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            195         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,093,707\n",
            "Trainable params: 2,601,607\n",
            "Non-trainable params: 2,492,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-adc0a3a7eeb0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gbrt_result = gbrt_minimize(func=multi_objective_function,\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             x0=default_params)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gbrt.py\u001b[0m in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m         base_estimator = cook_estimator(\"GBRT\", random_state=rng,\n\u001b[1;32m    178\u001b[0m                                         n_jobs=n_jobs)\n\u001b[0;32m--> 179\u001b[0;31m     return base_minimize(func, dimensions, base_estimator,\n\u001b[0m\u001b[1;32m    180\u001b[0m                          \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                          \u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random_starts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# evaluate y0 if only x0 is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# record through tell function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d15ac87a5604>\u001b[0m in \u001b[0;36mmulti_objective_function\u001b[0;34m(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     history = model.fit([x_train_encoded, x_train_encoded],\n\u001b[0m\u001b[1;32m     12\u001b[0m                         \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "gbrt_result = gbrt_minimize(func=multi_objective_function,\n",
        "                            dimensions=search_space,\n",
        "                            n_calls=12,\n",
        "                            n_jobs=-1,\n",
        "                            x0=default_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXJR-gol4djp"
      },
      "outputs": [],
      "source": [
        "# TODO: data frame summarizing parameter search\n",
        "gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
        "print(\"Best Hyperparameters:\", gbrt_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IifUQ2ju4djp"
      },
      "outputs": [],
      "source": [
        "model = define_multi_channel_lstm_model(gbrt_best_params['num_lstm_layersA'],\n",
        "                                        gbrt_best_params['num_lstm_layersB'],\n",
        "                                        gbrt_best_params['num_lstm_unitsA'],\n",
        "                                        gbrt_best_params['num_lstm_unitsB'],\n",
        "                                        )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
        "history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                    y_train_encoded,\n",
        "                    validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                    epochs=epochs, # TODO\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=2\n",
        "                    )\n",
        "plot_development(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAqMaRSI4djp"
      },
      "outputs": [],
      "source": [
        "model.evaluate([x_train_encoded, x_train_encoded], y_train_encoded)\n",
        "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_val_encoded, x_val_encoded], y_val_encoded, verbose=0)\n",
        "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_test_encoded, x_test_encoded], y_test_encoded, verbose=0)\n",
        "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
        "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
        "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
