{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from numpy import asarray\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
    "\n",
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer  \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# DATASET\n",
    "DATASET_COLUMNS = ['Id', 'Review', 'Sentiment']\n",
    "# Define a dictionary to map sentiment values to category names\n",
    "senti_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
    "senti_categories = list(senti_labels.values())\n",
    "NUM_of_CLASSES = 3\n",
    "\n",
    "input_folder_path = \"./pls/Thesis_Jupyter_Final/src/input/\"\n",
    "processed_folder_path = \"./pls/Thesis_Jupyter_Final/src/input/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# just checkıng gpu ıs avaılable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(input_folder_path, \"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(input_folder_path, \"val.csv\"))\n",
    "test = pd.read_csv(os.path.join(input_folder_path, \"test.csv\"))\n",
    "\n",
    "x_train = train['x']\n",
    "y_train = train['y']\n",
    "x_val = val['x']\n",
    "y_val = val['y']\n",
    "x_test = test['x']\n",
    "y_test = test['y']\n",
    "\n",
    "x_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_x.npy\"))\n",
    "y_train_encoded = np.load(os.path.join(processed_folder_path, \"train_encoded_y.npy\"))\n",
    "x_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_x.npy\"))\n",
    "y_val_encoded = np.load(os.path.join(processed_folder_path, \"val_encoded_y.npy\"))\n",
    "x_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_x.npy\"))\n",
    "y_test_encoded = np.load(os.path.join(processed_folder_path, \"test_encoded_y.npy\"))\n",
    "\n",
    "w2v_embedding_vectors = np.load(os.path.join(processed_folder_path, \"embedding_matrix.npy\"))\n",
    "print(w2v_embedding_vectors)\n",
    "\n",
    "%store -r embedding_vocab_size\n",
    "%store -r EMBEDDING_DIM\n",
    "%store -r max_seq_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "def calculate_metrics(score):\n",
    "    acc =  score[1]\n",
    "    loss = score[0]\n",
    "\n",
    "    print(f\"Accuracy: {acc:.2%}\")\n",
    "    print(f\"Loss: {loss:.2f}\")\n",
    "    \n",
    "    return acc, loss\n",
    "\n",
    "def calculate_classification_report(y, y_pred, labels):\n",
    "    report = classification_report(y, y_pred, labels=labels)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
    "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=labels)\n",
    "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, model_name, x_encoded, y_encoded, y=None, only_metrics=True):    \n",
    "    y_pred_prob = model.predict(x_encoded)\n",
    "\n",
    "    print(f\"*{model_name}\")\n",
    "    \n",
    "    score = model.evaluate(x_encoded, y_encoded, verbose=0)\n",
    "    calculate_metrics(score)\n",
    "    \n",
    "    senti_labels = ['negative', 'neutral', 'positive'] #TODO: to constants\n",
    "    \n",
    "    if not only_metrics:\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1) + 1\n",
    "        calculate_classification_report(y, y_pred, labels=senti_labels)\n",
    "        plot_confusion_matrix(y, y_pred, labels=senti_labels)\n",
    "    \n",
    "    print()\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
    "    for i, label in enumerate(y):\n",
    "        y_encoded[i, label - 1] = 1\n",
    "\n",
    "    return y_encoded\n",
    "\n",
    "def plot_roc_curve(prob_test_vec, y_test, labels):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    labels = labels\n",
    "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
    "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_test[:, senti],\n",
    "            prob_test_vec[:, senti],\n",
    "            name=f\"ROC curve for {labels[senti]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "        )\n",
    "    \n",
    "def calculate_OvR_roc_auc_score(model, x, y, x_test, y_test, labels): #average??\n",
    "    #y = one_hot_encode(y)\n",
    "    #y_test = one_hot_encode(y_test)\n",
    "\n",
    "    ovr_model = OneVsRestClassifier(model).fit(x, y)\n",
    "    prob_test_vec = ovr_model.predict_proba(x_test)\n",
    "    \n",
    "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
    "    for _ in range(NUM_of_CLASSES):\n",
    "        fpr.append(0)\n",
    "        tpr.append(0)\n",
    "        thresholds.append(0)\n",
    "        auc_score.append(0)\n",
    "    \n",
    "    for i in range(NUM_of_CLASSES):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
    "        auc_score[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    print(f\"AUC score: {auc_score}\")\n",
    "    averaged_auc_score = (sum(auc_score) / NUM_of_CLASSES)\n",
    "    print(f\"Averaged AUC score: {averaged_auc_score:.2f}\")\n",
    "    \n",
    "    plot_roc_curve(prob_test_vec, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "def plot_development(history):\n",
    "    acc =  history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "num_output_classes = 3\n",
    "batch_size= 32\n",
    "epochs=30\n",
    "\n",
    "num_lstm_layersA = Integer(low=1, high=3, name='num_lstm_layers')\n",
    "num_lstm_layersB = Integer(low=1, high=3, name='num_lstm_layers')\n",
    "num_lstm_unitsA = Categorical([16, 32, 64, 128], name='num_lstm_units') \n",
    "num_lstm_unitsB = Categorical([16, 32, 64, 128], name='num_lstm_units') \n",
    "learning_rate = Categorical([1e-4, 1e-3, 1e-2], name='learning_rate')\n",
    "adam_decay = Categorical([1e-6, 1e-4, 1e-2], name=\"adam_decay\")\n",
    "\n",
    "search_space = [\n",
    "            num_lstm_layersA,\n",
    "            num_lstm_layersB,\n",
    "            num_lstm_unitsA,\n",
    "            num_lstm_unitsB,\n",
    "            learning_rate,\n",
    "            adam_decay\n",
    "            ]\n",
    "\n",
    "# Specify one or more initial points for the search of optimal parameter\n",
    "default_params = [1, \n",
    "                  1, \n",
    "                  16,\n",
    "                  16, \n",
    "                  1e-3,\n",
    "                  1e-3 \n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "def define_multi_channel_lstm_model(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB, learning_rate, adam_decay):\n",
    "    # Vocabulary-based embedding layer\n",
    "    inputsA = Input(shape=(max_seq_length,), name=\"input regular embeddings\")\n",
    "    # Word2Vec embedding layer\n",
    "    inputsB = Input(shape=(max_seq_length,), name=\"input word2vec embeddings\")\n",
    "    \n",
    "    # Define an embedding layer for each input\n",
    "    embeddingsA = Embedding(embedding_vocab_size, EMBEDDING_DIM, input_length=max_seq_length, name=\"embeddingsA\")(inputsA)\n",
    "    embeddingsB = Embedding(embedding_vocab_size, EMBEDDING_DIM, input_length=max_seq_length, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
    "    \n",
    "    # Pass both embeddings through their own LSTM layers\n",
    "    lstm_layersA = embeddingsA\n",
    "    for i in range(num_lstm_layersA):\n",
    "        nameA = 'layer_lstmA_{0}'.format(i+1)\n",
    "        if i < num_lstm_layers-1:\n",
    "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=True, name=nameA)(lstm_layersA)\n",
    "        else:\n",
    "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=False, name=nameA)(lstm_layersA)\n",
    "        \n",
    "    lstm_layersB = embeddingsB\n",
    "    for i in range(num_lstm_layersB):\n",
    "        nameA = 'layer_lstmB_{0}'.format(i+1)\n",
    "        if i < num_lstm_layers-1:\n",
    "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=True, name=nameA)(lstm_layersB)\n",
    "        else:\n",
    "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=False, name=nameA)(lstm_layersB)\n",
    "        \n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
    "\n",
    "    # Dense layer for the merged inputs & output Layer\n",
    "    outputs = Dense(num_output_classes, activation='softmax', name=\"output\")(merged)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    adam = Adam(learning_rate=learning_rate, decay=adam_decay)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "@use_named_args(dimensions=search_space)\n",
    "def multi_objective_function(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB, learning_rate, adam_decay, batch_size):\n",
    "\n",
    "    model = define_multi_channel_lstm_model(num_lstm_layersA=num_lstm_layersA,\n",
    "                                            num_lstm_layersB=num_lstm_layersB,\n",
    "                                            num_lstm_unitsA=num_lstm_unitsA,\n",
    "                                            num_lstm_unitsB=num_lstm_unitsB,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            adam_decay=adam_decay\n",
    "                                            )\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(x_train_encoded,\n",
    "                        y_train_encoded,\n",
    "                        validation_data=(x_val_encoded, y_val_encoded),\n",
    "                        epochs=epochs, # TODO\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "    #return the validation accuracy for the last epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    loss = history.history['val_loss'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Loss: {loss:.2}\\n\")\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    \n",
    "    # the optimizer aims for the lowest score, so we return our negative accuracy\n",
    "    return -accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "gp_result = gp_minimize(func=multi_objective_function,\n",
    "                            dimensions=search_space,\n",
    "                            n_calls=12,\n",
    "                            noise= 0.01,\n",
    "                            n_jobs=-1,\n",
    "                            kappa = 5,\n",
    "                            x0=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "# TODO data frame summarizing parameter search\n",
    "gp_best_params = {param.name: value for param, value in zip(gp_result.space, gp_result.x)}\n",
    "print(\"Best Hyperparameters:\", gp_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "model = define_multi_channel_lstm_model(gp_best_params['num_lstm_layersA'],\n",
    "                                        gp_best_params['num_lstm_layersB'],\n",
    "                                        gp_best_params['num_lstm_unitsA'], \n",
    "                                        gp_best_params['num_lstm_unitsB'],\n",
    "                                        gp_best_params['learning_rate'], \n",
    "                                        gp_best_params['adam_decay']\n",
    "                                        )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
    "history = model.fit(x_train_encoded,\n",
    "                        y_train_encoded,\n",
    "                        validation_data=(x_val_encoded, y_val_encoded),\n",
    "                        epochs=epochs, # TODO\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "plot_development(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_train_encoded, y_train_encoded)\n",
    "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate(x_val_encoded, y_val_encoded, verbose=0)\n",
    "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate(x_test_encoded, y_test_encoded, verbose=0)\n",
    "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
    "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
    "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "gbrt_result = gbrt_minimize(func=objective_function,\n",
    "                            dimensions=search_space,\n",
    "                            n_calls=12,\n",
    "                            n_jobs=-1,\n",
    "                            x0=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "# TODO data frame summarizing parameter search\n",
    "gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
    "print(\"Best Hyperparameters:\", gbrt_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "model = define_multi_channel_lstm_model(gbrt_best_params['num_lstm_layersA'],\n",
    "                                        gbrt_best_params['num_lstm_layersB'],\n",
    "                                        gbrt_best_params['num_lstm_unitsA'], \n",
    "                                        gbrt_best_params['num_lstm_unitsB'],\n",
    "                                        gbrt_best_params['learning_rate'], \n",
    "                                        gbrt_best_params['adam_decay'],\n",
    "                                        )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
    "history = model.fit(x_train_encoded,\n",
    "                        y_train_encoded,\n",
    "                        validation_data=(x_val_encoded, y_val_encoded),\n",
    "                        epochs=20, # TODO\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "plot_development(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://a100gpu6:8889/'. Verify the server is running and reachable. (The Jupyter notebook server failed to launch in time)."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_train_encoded, y_train_encoded)\n",
    "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate(x_val_encoded, y_val_encoded, verbose=0)\n",
    "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
    "\n",
    "model.evaluate(x_test_encoded, y_test_encoded, verbose=0)\n",
    "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
    "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
    "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
