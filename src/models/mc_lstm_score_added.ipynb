{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekinfergan/Thesis_Jupyter_Final/blob/main/src/models/mc_lstm_score_added.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IeGWBYI7QVM"
      },
      "source": [
        "# Multi-Channel LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLo6SAsAlf2",
        "outputId": "020626b8-1db6-4489-e305-e54675395baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thesis_Jupyter_Final'...\n",
            "remote: Enumerating objects: 879, done.\u001b[K\n",
            "remote: Counting objects: 100% (299/299), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 879 (delta 132), reused 295 (delta 128), pack-reused 580\u001b[K\n",
            "Receiving objects: 100% (879/879), 189.03 MiB | 31.18 MiB/s, done.\n",
            "Resolving deltas: 100% (450/450), done.\n",
            "Updating files: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ekinfergan/Thesis_Jupyter_Final.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu8fYz7JAojH",
        "outputId": "6b313be0-bca8-47da-b5d2-5fa381415fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis_Jupyter_Final\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd Thesis_Jupyter_Final\n",
        "!git pull\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D94-Epo4AtnH",
        "outputId": "a5144cab-f480-4bf6-eb0c-8808d2f308b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.0\n",
            "    Uninstalling numpy-1.25.0:\n",
            "      Successfully uninstalled numpy-1.25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLN7F7oYL9Ad",
        "outputId": "bbc417bd-2879-4afc-add9-9b37087985e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-wt9xbtmg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-wt9xbtmg\n",
            "  Resolved https://github.com/scikit-optimize/scikit-optimize.git to commit a2369ddbc332d16d8ff173b12404b03fea472492\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize==0.9.0)\n",
            "  Using cached pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.0) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize==0.9.0) (3.1.0)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.0-py2.py3-none-any.whl size=100250 sha256=a977b3c111f98e517f8e0d074fd47ac033b6882ab78189c1245077e2ae974072\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-moi5bpos/wheels/2f/f0/ed/db529a96372d05bd34f6c3a2fa7c08ef7a8314315ac46e49d7\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qBccKNo67QVP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from numpy import asarray\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from itertools import cycle\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
        "\n",
        "import skopt\n",
        "from skopt import gbrt_minimize, gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn9_Vjsx7QVT",
        "outputId": "dad717a3-6eeb-4237-9e0e-ce4cb0ce664e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# just checkıng gpu ıs avaılable\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnmdbVk07QVh",
        "outputId": "7d9cc8a4-2e80-423b-da52-15668894c3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis_Jupyter_Final/src/\n"
          ]
        }
      ],
      "source": [
        "script_dir = os.path.dirname(os.path.abspath('mc_lstm.ipynb'))\n",
        "data_path = os.path.join(script_dir, 'Thesis_Jupyter_Final/src/')\n",
        "os.getcwd()\n",
        "print(data_path)\n",
        "\n",
        "input_folder_path = os.path.join(data_path, 'input')\n",
        "processed_folder_path = os.path.join(data_path, 'input/processed/normal')\n",
        "results_folder_path = \"results/LSTM_results\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(results_folder_path):\n",
        "    os.makedirs(results_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GLNGtnAb7QVj"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "# Define a dictionary to map sentiment values to category names\n",
        "senti_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
        "senti_categories = list(senti_labels.values())\n",
        "NUM_of_CLASSES = 3\n",
        "\n",
        "VOCAB_SIZE = 11395\n",
        "MAX_SEQ_LEN = 449\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_OUTPUT_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgJczUT07QVj",
        "outputId": "fafeaf7f-b70d-40da-e09b-b0d72c1cd1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_encoded:\n",
            "[[  96  549  929 ...    0    0    0]\n",
            " [ 453  240 1125 ...    0    0    0]\n",
            " [1260   67  312 ...    0    0    0]\n",
            " [ 127 1352 6694 ...    0    0    0]\n",
            " [ 529   10   69 ...    0    0    0]]\n",
            "\n",
            "embedding vectors: [-0.57674998 -0.42304999  0.27188    -0.31986001  0.18842   ]...\n",
            "\n",
            "x_train_scores:\n",
            "[[-0.875 -0.5    0.    ...  0.     0.     0.   ]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]\n",
            " [-0.625  0.125  0.375 ...  0.     0.     0.   ]\n",
            " [ 0.     0.25   0.    ...  0.     0.     0.   ]\n",
            " [-0.125 -0.25   0.    ...  0.     0.     0.   ]]\n",
            "\n",
            "y_train_encoded:\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(os.path.join(processed_folder_path, \"train.csv\"))\n",
        "val = pd.read_csv(os.path.join(processed_folder_path, \"val.csv\"))\n",
        "test = pd.read_csv(os.path.join(processed_folder_path, \"test.csv\"))\n",
        "\n",
        "x_train = train['x']\n",
        "y_train = train['y']\n",
        "x_val = val['x']\n",
        "y_val = val['y']\n",
        "x_test = test['x']\n",
        "y_test = test['y']\n",
        "import pickle\n",
        "\n",
        "# Load encoded sequences\n",
        "with open(os.path.join(processed_folder_path, \"x_train_encoded.pkl\"), \"rb\") as f:\n",
        "    x_train_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_val_encoded.pkl\"), \"rb\") as f:\n",
        "    x_val_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_test_encoded.pkl\"), \"rb\") as f:\n",
        "    x_test_encoded = pickle.load(f)\n",
        "print(f\"x_train_encoded:\\n{x_train_encoded[:5]}\\n\")\n",
        "\n",
        "# Load embedding vectors\n",
        "with open(os.path.join(processed_folder_path, \"embedding_matrix.pkl\"), \"rb\") as f:\n",
        "    w2v_embedding_vectors = pickle.load(f)\n",
        "print(f\"embedding vectors: {w2v_embedding_vectors[10][:5]}...\\n\")\n",
        "\n",
        "# Load sentiment scores\n",
        "with open(os.path.join(processed_folder_path, \"x_train_scores_padded.pkl\"), \"rb\") as f:\n",
        "    x_train_scores = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_val_scores_padded.pkl\"), \"rb\") as f:\n",
        "    x_val_scores = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_test_scores_padded.pkl\"), \"rb\") as f:\n",
        "    x_test_scores = pickle.load(f)\n",
        "print(f\"x_train_scores:\\n{x_train_scores[:5]}\\n\")\n",
        "\n",
        "# Load encoded labels\n",
        "with open(os.path.join(processed_folder_path, \"y_train_encoded.pkl\"), \"rb\") as f:\n",
        "    y_train_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"y_val_encoded.pkl\"), \"rb\") as f:\n",
        "    y_val_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"y_test_encoded.pkl\"), \"rb\") as f:\n",
        "    y_test_encoded = pickle.load(f)\n",
        "print(f\"y_train_encoded:\\n{y_train_encoded[:5]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHyFkfrk7QVk"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "eIN6ACnP7QVk"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(y):\n",
        "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
        "    for i, label in enumerate(y):\n",
        "        y_encoded[i, label - 1] = 1\n",
        "\n",
        "    return y_encoded\n",
        "\n",
        "def calculate_classification_report(y, y_pred, labels, target_names):\n",
        "    report = classification_report(y, y_pred, labels=labels, target_names=target_names)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, res_path):\n",
        "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
        "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=labels)\n",
        "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
        "    plt.title(f'Confusion Matrix')\n",
        "    plt.savefig(os.path.join(res_path, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def plot_roc_curve(prob_test_vec, y_test, labels, res_path):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    labels = labels\n",
        "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
        "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
        "        RocCurveDisplay.from_predictions(\n",
        "            y_test[:, senti],\n",
        "            prob_test_vec[:, senti],\n",
        "            name=f\"ROC curve for {labels[senti]}\",\n",
        "            color=color,\n",
        "            ax=ax,\n",
        "        )\n",
        "    plt.savefig(os.path.join(res_path, \"roc_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def calculate_roc_auc_score(model, model_name, x_test, y_test, labels, res_path):\n",
        "    prob_test_vec = model.predict(x_test)\n",
        "\n",
        "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
        "    for _ in range(NUM_of_CLASSES):\n",
        "        fpr.append(0)\n",
        "        tpr.append(0)\n",
        "        thresholds.append(0)\n",
        "        auc_score.append(0)\n",
        "\n",
        "    for i in range(NUM_of_CLASSES):\n",
        "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
        "        auc_score[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    averaged_auc_score = (sum(auc_score) / NUM_of_CLASSES)\n",
        "\n",
        "    with open(os.path.join(res_path, f\"{model_name}_results.txt\"), \"a\") as f:\n",
        "        f.write(f\"AUC score: {auc_score}\\n\")\n",
        "        f.write(f\"Averaged AUC score: {averaged_auc_score:.2f}\\n\")\n",
        "\n",
        "    plot_roc_curve(prob_test_vec, y_test, labels, res_path=res_path)\n",
        "\n",
        "\n",
        "def plot_development(history):\n",
        "    acc =  history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title('Training and validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig(os.path.join(results_folder_path, \"development_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def get_results(y_pred, y, x, score, history, model, model_name, params, res_path):\n",
        "    if not os.path.exists(res_path):\n",
        "        os.makedirs(res_path)\n",
        "\n",
        "    # Convert to one hot vectors\n",
        "    y_classes = np.argmax(y, axis=1) + 1\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1) + 1\n",
        "\n",
        "    print(y_pred.shape)\n",
        "    print(y_classes.shape)\n",
        "    print(y_pred_classes.shape)\n",
        "\n",
        "    print(f\"Accuracy: {score[1]:.2%}\")\n",
        "    print(f\"Loss: {score[0]:.2f}\")\n",
        "\n",
        "    with open(os.path.join(res_path, f\"{model_name}_results.txt\"), \"w\") as f:\n",
        "        f.write(f\"*{model_name}\\n\")\n",
        "        f.write(f\"Optimizer Params: {params}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Accuracy: {score[1]:.2f}%\\n\")\n",
        "        f.write(f\"Loss: {score[0]:.2f}\\n\")\n",
        "\n",
        "        report = calculate_classification_report(y_classes, y_pred_classes, labels=np.unique(y_classes), target_names=senti_categories)\n",
        "        if report is not None:\n",
        "            f.write(\"Classification Report:\\n\")\n",
        "            f.write(report)\n",
        "        else:\n",
        "            print(\"Failed to generate classification report\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        plot_confusion_matrix(y_classes, y_pred_classes, senti_categories, res_path)\n",
        "        plot_development(history)\n",
        "        #calculate_roc_auc_score(model, model_name, x, y, senti_categories, res_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "j1oGW90j7QVm",
        "outputId": "99ba0c64-4044-4e52-b787-50acc4b43368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embeddings_layer (Embedding  (None, 449, 100)         1139500   \n",
            " )                                                               \n",
            "                                                                 \n",
            " hidden_layer (LSTM)         (None, 64)                42240     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,181,935\n",
            "Trainable params: 42,435\n",
            "Non-trainable params: 1,139,500\n",
            "_________________________________________________________________\n",
            "2563/2563 [==============================] - 56s 21ms/step - loss: 1.0497 - accuracy: 0.4878 - val_loss: 0.8187 - val_accuracy: 0.8674\n",
            "372/372 [==============================] - 3s 7ms/step\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 0.8350 - accuracy: 0.8404\n",
            "(11899, 3)\n",
            "(11899,)\n",
            "(11899,)\n",
            "Accuracy: 84.04%\n",
            "Loss: 0.83\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00       924\n",
            "     Neutral       0.00      0.00      0.00       975\n",
            "    Positive       0.84      1.00      0.91     10000\n",
            "\n",
            "    accuracy                           0.84     11899\n",
            "   macro avg       0.28      0.33      0.30     11899\n",
            "weighted avg       0.71      0.84      0.77     11899\n",
            "\n",
            "Failed to generate classification report\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home2/s3985113/venv/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home2/s3985113/venv/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home2/s3985113/venv/thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "372/372 [==============================] - 3s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "# input layer is sequence of integers (words)\n",
        "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddings_layer\")) # part of input layer as it transforms integers into dense vectors, input shape = (None, MAX_SEQ_LEN)\n",
        "model.add(LSTM(64, name='hidden_layer')) # hidden layer\n",
        "model.add(Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output_layer\"))\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train_encoded, y_train_encoded, validation_data=(x_val_encoded, y_val_encoded), batch_size=16, epochs=1)\n",
        "\n",
        "y_pred = model.predict(x_test_encoded)\n",
        "score = model.evaluate(x_test_encoded, y_test_encoded)\n",
        "\n",
        "get_results(y_pred, y_test_encoded, x_test_encoded, score, history, model, \"LSTM\", model.optimizer.get_config(), results_folder_path)\n",
        "\n",
        "del model\n",
        "\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NHXsZnqeArB",
        "outputId": "962c72fd-89c8-495b-9d81-f6181980b08b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_classes = np.argmax(y_test_encoded, axis=1) + 1\n",
        "np.unique(y_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFpwdRFOeArC",
        "outputId": "8d3e5ea8-efa4-4156-d614-6ee0dc74072a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (3444485417.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[75], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.add(Embedding(input_length=MAX_SEQ_LEN,  1, name=\"embeddings_layer\")) # part of input layer as it transforms integers into dense vectors, input shape = (None, MAX_SEQ_LEN)\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ],
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "# input layer is sequence of integers (words)\n",
        "model.add(Embedding(input_length=MAX_SEQ_LEN,  1, name=\"embeddings_layer\")) # part of input layer as it transforms integers into dense vectors, input shape = (None, MAX_SEQ_LEN)\n",
        "model.add(LSTM(64, name='hidden_layer')) # hidden layer\n",
        "model.add(Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output_layer\"))\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train_scores, y_train_encoded, validation_data=(x_val_scores, y_val_encoded), batch_size=16, epochs=2)\n",
        "\n",
        "y_pred = model.predict(x_test_scores)\n",
        "score = model.evaluate(x_test_scores, y_test_encoded)\n",
        "\n",
        "get_results(y_pred, y_test_encoded, x_test_scores, score, history, model, \"LSTM\", model.optimizer.get_config(), results_folder_path)\n",
        "\n",
        "del model\n",
        "\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Z36YUqHTeArC",
        "outputId": "14654382-7a55-41e8-a6ed-c6e00f369bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word2vec_embeddings (Inp  [(None, 449)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " input_sentiwordnet_scores (Inp  [(None, 449, 1)]    0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 449, 100)     1139500     ['input_word2vec_embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 449, 64)      16896       ['input_sentiwordnet_scores[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 449, 64)      42240       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " layer_lstmA_2 (LSTM)           (None, 32)           12416       ['layer_lstmA_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmB_2 (LSTM)           (None, 32)           12416       ['layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['layer_lstmA_2[0][0]',          \n",
            "                                                                  'layer_lstmB_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 16)           1040        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            51          ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,224,559\n",
            "Trainable params: 85,059\n",
            "Non-trainable params: 1,139,500\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 41000 samples, validate on 11529 samples\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  240/41000 [..............................] - ETA: 34:05 - loss: 0.2203 - accuracy: 0.3875"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-b38617a636cd>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train_scores_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_scores_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_scores_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         return fit_loop(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4608\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4610\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "K.clear_session()\n",
        "x_train_scores_exp = np.expand_dims(x_train_scores, axis=-1)\n",
        "x_val_scores_exp = np.expand_dims(x_val_scores, axis=-1)\n",
        "x_test_scores_exp = np.expand_dims(x_test_scores, axis=-1)\n",
        "\n",
        "def define_multi_channel_lstm_model():\n",
        "     # SentiWordNet scores layer\n",
        "    inputsA = Input(shape=(MAX_SEQ_LEN, 1), name=\"input_sentiwordnet_scores\")\n",
        "\n",
        "    # Word2Vec embedding layer\n",
        "    inputsB = Input(shape=(MAX_SEQ_LEN,), name=\"input_word2vec_embeddings\")\n",
        "    embeddingsB = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
        "\n",
        "    # Pass both embeddings through their own LSTM layers\n",
        "    lstm_layersA = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_1')(inputsA)\n",
        "    lstm_layersA = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmA_2')(lstm_layersA)\n",
        "\n",
        "    lstm_layersB = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_1')(embeddingsB)\n",
        "    lstm_layersB = LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, name='layer_lstmB_2')(lstm_layersB)\n",
        "\n",
        "\n",
        "    # Concatenate the two inputs\n",
        "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
        "\n",
        "    # Additional Dense layer for dimensionality reduction\n",
        "    dense_layer = Dense(16, activation='relu', name=\"dense_layer\")(merged)\n",
        "\n",
        "    # Dense layer for the merged inputs & output Layer\n",
        "    outputs = Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output\")(dense_layer)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    rmsprop = RMSprop(learning_rate=0.001) # default is 0.001\n",
        "    model.compile(optimizer=rmsprop, loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 20\n",
        "\n",
        "model = define_multi_channel_lstm_model()\n",
        "\n",
        "checkpoint_acc = ModelCheckpoint('models/lstm_checkpoint_acc.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "checkpoint_loss = ModelCheckpoint('models/lstm_checkpoint_loss.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
        "history = model.fit([x_train_scores_exp, x_train_encoded], y_train_encoded, validation_data=([x_val_scores_exp, x_val_encoded], y_val_encoded), callbacks=[early_stopping, checkpoint_acc, checkpoint_loss, tensorboard_callback], batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "y_pred = model.predict([x_test_scores_exp, x_test_encoded])\n",
        "score = model.evaluate([x_test_scores_exp, x_test_encoded], y_test_encoded)\n",
        "\n",
        "get_results(y_pred, y_test_encoded, x_test_encoded, score, history, model, \"LSTM\", model.optimizer.get_config(), results_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_r9RfPdeArD"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPrSGJ177QVn"
      },
      "source": [
        "## Hypterparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CKvzLVM7QVn"
      },
      "outputs": [],
      "source": [
        "batch_size= 16\n",
        "epochs=30\n",
        "\n",
        "num_lstm_layersA = Integer(low=1, high=3, name='num_lstm_layersA')\n",
        "num_lstm_layersB = Integer(low=1, high=3, name='num_lstm_layersB')\n",
        "num_lstm_unitsA = Categorical([32, 64], name='num_lstm_unitsA')\n",
        "num_lstm_unitsB = Categorical([32, 64], name='num_lstm_unitsB')\n",
        "#learning_rate = Categorical([1e-2], name='learning_rate')\n",
        "#adam_decay = Categorical([1e-6, 1e-4, 1e-2], name=\"adam_decay\")\n",
        "\n",
        "search_space = [\n",
        "            num_lstm_layersA,\n",
        "            num_lstm_layersB,\n",
        "            num_lstm_unitsA,\n",
        "            num_lstm_unitsB,\n",
        "            ]\n",
        "\n",
        "# Specify one or more initial points for the search of optimal parameter\n",
        "default_params = [1,\n",
        "                  1,\n",
        "                  32,\n",
        "                  32,\n",
        "                  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFAG6ZRP7QVn"
      },
      "outputs": [],
      "source": [
        "def define_multi_channel_lstm_model(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "     # SentiWordNet scores layer\n",
        "    inputsA = Input(shape=(MAX_SEQ_LEN, 1), name=\"input sentiwordnet scores\")\n",
        "\n",
        "    # Word2Vec embedding layer\n",
        "    inputsB = Input(shape=(MAX_SEQ_LEN,), name=\"input word2vec embeddings\")\n",
        "\n",
        "    # Define an embedding layer for each input\n",
        "    embeddingsB = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
        "\n",
        "    # Pass both embeddings through their own LSTM layers\n",
        "    lstm_layersA = inputsA\n",
        "    for i in range(num_lstm_layersA):\n",
        "        nameA = 'layer_lstmA_{0}'.format(i+1)\n",
        "        if i < num_lstm_layersA-1:\n",
        "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=True, name=nameA)(lstm_layersA)\n",
        "        else:\n",
        "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=False, name=nameA)(lstm_layersA)\n",
        "\n",
        "    lstm_layersB = embeddingsB\n",
        "    for i in range(num_lstm_layersB):\n",
        "        nameA = 'layer_lstmB_{0}'.format(i+1)\n",
        "        if i < num_lstm_layersB-1:\n",
        "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=True, name=nameA,)(lstm_layersB)\n",
        "        else:\n",
        "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=False, name=nameA)(lstm_layersB)\n",
        "\n",
        "\n",
        "    # Concatenate the two inputs\n",
        "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
        "\n",
        "    # Additional Dense layer for dimensionality reduction\n",
        "    dense_layer = Dense(16, activation='relu', name=\"dense_layer\")(merged)\n",
        "\n",
        "    # Dense layer for the merged inputs & output Layer\n",
        "    outputs = Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output\")(dense_layer)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    rmsprop = RMSprop(learning_rate=0.001) # default is 0.001\n",
        "    model.compile(optimizer=rmsprop, loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmZDNHqf7QVo"
      },
      "outputs": [],
      "source": [
        "@use_named_args(dimensions=search_space)\n",
        "def multi_objective_function(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "\n",
        "    model = define_multi_channel_lstm_model(num_lstm_layersA=num_lstm_layersA,\n",
        "                                            num_lstm_layersB=num_lstm_layersB,\n",
        "                                            num_lstm_unitsA=num_lstm_unitsA,\n",
        "                                            num_lstm_unitsB=num_lstm_unitsB,\n",
        "                                            )\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                        y_train_encoded,\n",
        "                        validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                        epochs=epochs, # TODO\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=2\n",
        "                        )\n",
        "    #return the validation accuracy for the last epoch.\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "    loss = history.history['val_loss'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Loss: {loss:.2}\\n\")\n",
        "\n",
        "\n",
        "    # Delete the Keras model with these hyper-parameters from memory.\n",
        "    del model\n",
        "\n",
        "    # Clear the Keras session, otherwise it will keep adding new\n",
        "    # models to the same TensorFlow graph each time we create\n",
        "    # a model with a different set of hyper-parameters.\n",
        "    K.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    # the optimizer aims for the lowest score, so we return our negative accuracy\n",
        "    return -accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_jjoL_97QVo"
      },
      "source": [
        "## Gradient Boosted Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jev5XRL87QVp",
        "outputId": "315ba824-d7bc-40b2-fbdb-4746c757b4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input word2vec embeddings (Inp  [(None, 449)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " input sentiwordnet scores (Inp  [(None, 449, 1)]    0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 449, 100)     1139500     ['input word2vec embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 32)           4352        ['input sentiwordnet scores[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 32)           17024       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['layer_lstmA_1[0][0]',          \n",
            "                                                                  'layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 16)           1040        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            51          ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,161,967\n",
            "Trainable params: 22,467\n",
            "Non-trainable params: 1,139,500\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "2563/2563 - 95s - loss: 0.2108 - accuracy: 0.4878 - val_loss: 0.1535 - val_accuracy: 0.8674 - 95s/epoch - 37ms/step\n",
            "Epoch 2/30\n",
            "2563/2563 - 91s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1456 - val_accuracy: 0.8674 - 91s/epoch - 36ms/step\n",
            "Epoch 3/30\n",
            "2563/2563 - 91s - loss: 0.2104 - accuracy: 0.4879 - val_loss: 0.1521 - val_accuracy: 0.8674 - 91s/epoch - 35ms/step\n",
            "Epoch 4/30\n",
            "2563/2563 - 91s - loss: 0.2104 - accuracy: 0.4879 - val_loss: 0.1471 - val_accuracy: 0.8674 - 91s/epoch - 35ms/step\n",
            "Epoch 5/30\n",
            "2563/2563 - 91s - loss: 0.2104 - accuracy: 0.4879 - val_loss: 0.1460 - val_accuracy: 0.8674 - 91s/epoch - 36ms/step\n",
            "Epoch 6/30\n",
            "2563/2563 - 92s - loss: 0.2104 - accuracy: 0.4879 - val_loss: 0.1470 - val_accuracy: 0.8674 - 92s/epoch - 36ms/step\n",
            "Epoch 7/30\n",
            "2563/2563 - 91s - loss: 0.2104 - accuracy: 0.4879 - val_loss: 0.1518 - val_accuracy: 0.8674 - 91s/epoch - 35ms/step\n",
            "Accuracy: 86.74%\n",
            "Loss: 0.15\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input word2vec embeddings (Inp  [(None, 449)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 449, 100)     1139500     ['input word2vec embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " input sentiwordnet scores (Inp  [(None, 449, 1)]    0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 449, 64)      42240       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 449, 32)      4352        ['input sentiwordnet scores[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmB_2 (LSTM)           (None, 449, 64)      33024       ['layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmA_2 (LSTM)           (None, 32)           8320        ['layer_lstmA_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmB_3 (LSTM)           (None, 64)           33024       ['layer_lstmB_2[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 96)           0           ['layer_lstmA_2[0][0]',          \n",
            "                                                                  'layer_lstmB_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 16)           1552        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            51          ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,262,063\n",
            "Trainable params: 122,563\n",
            "Non-trainable params: 1,139,500\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n"
          ]
        }
      ],
      "source": [
        "gbrt_result = gbrt_minimize(func=multi_objective_function,\n",
        "                            dimensions=search_space,\n",
        "                            n_calls=12,\n",
        "                            n_jobs=-1,\n",
        "                            x0=default_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q-VNfO97QVp"
      },
      "outputs": [],
      "source": [
        "# TODO data frame summarizing parameter search\n",
        "gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
        "print(\"Best Hyperparameters:\", gbrt_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56s8zsrp7QVp"
      },
      "outputs": [],
      "source": [
        "model = define_multi_channel_lstm_model(gbrt_best_params['num_lstm_layersA'],\n",
        "                                        gbrt_best_params['num_lstm_layersB'],\n",
        "                                        gbrt_best_params['num_lstm_unitsA'],\n",
        "                                        gbrt_best_params['num_lstm_unitsB'],\n",
        "                                        )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
        "history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                    y_train_encoded,\n",
        "                    validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                    epochs=epochs, # TODO\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=2\n",
        "                    )\n",
        "plot_development(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKiDO3b7QVq"
      },
      "outputs": [],
      "source": [
        "model.evaluate([x_train_scores, x_train_encoded], y_train_encoded)\n",
        "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_val_scores, x_val_encoded], y_val_encoded, verbose=0)\n",
        "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_test_scores, x_test_encoded], y_test_encoded, verbose=0)\n",
        "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
        "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
        "#calculate_OvR_roc_auc_score(model, \"LSTM\", x_train, y_train, x_test, y_test, senti_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}