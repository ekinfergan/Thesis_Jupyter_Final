{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekinfergan/Thesis_Jupyter_Final/blob/main/src/models/mc_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_IeGWBYI7QVM"
      },
      "source": [
        "# Multi-Channel LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLo6SAsAlf2",
        "outputId": "ff9382e6-4a70-41d7-dcf6-65fda6fe9fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Thesis_Jupyter_Final' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ekinfergan/Thesis_Jupyter_Final.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu8fYz7JAojH",
        "outputId": "34902e45-16c9-463d-b41d-84a04bb70574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home2/s3985113/Thesis_Jupyter_Final\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), 2.84 KiB | 24.00 KiB/s, done.\n",
            "From https://github.com/ekinfergan/Thesis_Jupyter_Final\n",
            "   f0f2503..fe75b68  main       -> origin/main\n",
            "Updating f0f2503..fe75b68\n",
            "Fast-forward\n",
            " src/models/mc_lstm.ipynb | 349 \u001b[32m+++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--------------\u001b[m\n",
            " 1 file changed, 245 insertions(+), 104 deletions(-)\n",
            "/home2/s3985113\n"
          ]
        }
      ],
      "source": [
        "%cd Thesis_Jupyter_Final\n",
        "!git pull\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D94-Epo4AtnH",
        "outputId": "68fe17ba-85ef-4144-d133-778ba1bd9f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (2.11.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/flatbuffers/2.0.7-GCCcore-11.3.0/lib/python3.10/site-packages (from tensorflow) (20230331155526)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/h5py/3.7.0-foss-2022a/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (0.4.11)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow)\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from tensorflow) (1.22.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
            "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
            "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/thesis/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/thesis/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: mpi4py>=3.0.2 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from h5py>=2.9.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in ./venv/thesis/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.16.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/thesis/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/thesis/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/thesis/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/thesis/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/thesis/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/thesis/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: pyasn1, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.5.0\n",
            "    Uninstalling pyasn1-0.5.0:\n",
            "      Successfully uninstalled pyasn1-0.5.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Not uninstalling tensorflow-estimator at /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages, outside environment /home2/s3985113/venv/thesis\n",
            "    Can't uninstall 'tensorflow-estimator'. No files were found to uninstall.\n",
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLN7F7oYL9Ad",
        "outputId": "6934b4c8-70b8-4405-ea6f-922c11bc040e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-2otwbmew\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-2otwbmew\n",
            "  Resolved https://github.com/scikit-optimize/scikit-optimize.git to commit a2369ddbc332d16d8ff173b12404b03fea472492\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize==0.9.0)\n",
            "  Using cached pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.0) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize==0.9.0) (3.1.0)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.0-py2.py3-none-any.whl size=100250 sha256=82182c375007bab602b44f2495b46be23bdba259741eefc87eeb46388755c1cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_baspxx_/wheels/2f/f0/ed/db529a96372d05bd34f6c3a2fa7c08ef7a8314315ac46e49d7\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qBccKNo67QVP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-17 17:20:23.426944: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from numpy import asarray\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from itertools import cycle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
        "\n",
        "import skopt\n",
        "from skopt import gbrt_minimize, gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGoZtDZ4MBj8",
        "outputId": "c5305fd0-cdbc-4b68-cb77-cf1abffa0673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jun 16 22:02:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    47W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4qwI4igMDwx",
        "outputId": "d63302c8-b6ae-4ce7-ff37-45be938cf32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBEF4QV67QVT"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn9_Vjsx7QVT",
        "outputId": "96e54713-857a-45fb-f77a-af7a19711a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# just checkıng gpu ıs avaılable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hjcR6aH7QVg"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnmdbVk07QVh",
        "outputId": "ac3d7ea7-1c14-4897-98b2-b66eebb527f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home2/s3985113/Thesis_Jupyter_Final/src/\n"
          ]
        }
      ],
      "source": [
        "script_dir = os.path.dirname(os.path.abspath('mc_lstm.ipynb'))\n",
        "data_path = os.path.join(script_dir, 'Thesis_Jupyter_Final/src/')\n",
        "os.getcwd()\n",
        "print(data_path)\n",
        "\n",
        "input_folder_path = os.path.join(data_path, 'input')\n",
        "processed_folder_path = os.path.join(data_path, 'input/processed')\n",
        "results_folder_path = \"results\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(results_folder_path):\n",
        "    os.makedirs(results_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GLNGtnAb7QVj"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "# Define a dictionary to map sentiment values to category names\n",
        "senti_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
        "senti_categories = list(senti_labels.values())\n",
        "NUM_of_CLASSES = 3\n",
        "\n",
        "VOCAB_SIZE = 11354\n",
        "MAX_SEQ_LEN = 430\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_OUTPUT_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgJczUT07QVj",
        "outputId": "1f0789cb-126a-4502-a622-245204e43c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_encoded:\n",
            "[[  96  561  851 ...    0    0    0]\n",
            " [ 423  240 1166 ...    0    0    0]\n",
            " [1205   62  299 ...    0    0    0]\n",
            " [ 133 1322 5760 ...    0    0    0]\n",
            " [ 502    7   64 ...    0    0    0]]\n",
            "\n",
            "embedding vectors: [ 0.16271   0.18905  -0.046571 -0.05714  -0.16403 ]...\n",
            "\n",
            "x_train_scores:\n",
            "[[-0.875 -0.5    0.    ...  0.     0.     0.   ]\n",
            " [ 0.     0.     0.    ...  0.     0.     0.   ]\n",
            " [-0.625  0.125  0.375 ...  0.     0.     0.   ]\n",
            " [ 0.     0.25   0.    ...  0.     0.     0.   ]\n",
            " [-0.125 -0.25   0.    ...  0.     0.     0.   ]]\n",
            "\n",
            "y_train_encoded:\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(os.path.join(input_folder_path, \"train.csv\"))\n",
        "val = pd.read_csv(os.path.join(input_folder_path, \"val.csv\"))\n",
        "test = pd.read_csv(os.path.join(input_folder_path, \"test.csv\"))\n",
        "\n",
        "x_train = train['x']\n",
        "y_train = train['y']\n",
        "x_val = val['x']\n",
        "y_val = val['y']\n",
        "x_test = test['x']\n",
        "y_test = test['y']\n",
        "\n",
        "x_train_encoded = np.load(os.path.join(processed_folder_path, \"x_train_encoded.npy\"))\n",
        "x_val_encoded = np.load(os.path.join(processed_folder_path, \"x_val_encoded.npy\"))\n",
        "x_test_encoded = np.load(os.path.join(processed_folder_path, \"x_test_encoded.npy\"))\n",
        "print(f\"x_train_encoded:\\n{x_train_encoded[:5]}\\n\")\n",
        "\n",
        "w2v_embedding_vectors = np.load(os.path.join(processed_folder_path, \"embedding_matrix.npy\"))\n",
        "print(f\"embedding vectors: {w2v_embedding_vectors[10][:5]}...\\n\")\n",
        "\n",
        "x_train_scores = np.load(os.path.join(processed_folder_path, \"x_train_scores_padded.npy\"))\n",
        "x_val_scores = np.load(os.path.join(processed_folder_path, \"x_val_scores_padded.npy\"))\n",
        "x_test_scores = np.load(os.path.join(processed_folder_path, \"x_test_scores_padded.npy\"))\n",
        "print(f\"x_train_scores:\\n{x_train_scores[:5]}\\n\")\n",
        "\n",
        "y_train_encoded = np.load(os.path.join(processed_folder_path, \"y_train_encoded.npy\"))\n",
        "y_val_encoded = np.load(os.path.join(processed_folder_path, \"y_val_encoded.npy\"))\n",
        "y_test_encoded = np.load(os.path.join(processed_folder_path, \"y_test_encoded.npy\"))\n",
        "print(f\"y_train_encoded:\\n{y_train_encoded[:5]}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MHyFkfrk7QVk"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eIN6ACnP7QVk"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(score):\n",
        "    acc =  score[1]\n",
        "    loss = score[0]\n",
        "\n",
        "    print(f\"Accuracy: {acc:.2%}\")\n",
        "    print(f\"Loss: {loss:.2f}\")\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def calculate_classification_report(y, y_pred, labels):\n",
        "    report = classification_report(y, y_pred, labels=labels)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels):\n",
        "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
        "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=labels)\n",
        "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
        "    plt.title(f'Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, model_name, x_encoded, y_encoded, y=None, only_metrics=True):\n",
        "    y_pred_prob = model.predict(x_encoded)\n",
        "\n",
        "    print(f\"*{model_name}\")\n",
        "\n",
        "    score = model.evaluate(x_encoded, y_encoded, verbose=0)\n",
        "    calculate_metrics(score)\n",
        "\n",
        "    senti_labels = ['negative', 'neutral', 'positive'] #TODO: to constants\n",
        "\n",
        "    if not only_metrics:\n",
        "        y_pred = np.argmax(y_pred_prob, axis=1) + 1\n",
        "        calculate_classification_report(y, y_pred, labels=senti_labels)\n",
        "        plot_confusion_matrix(y, y_pred, labels=senti_labels)\n",
        "\n",
        "    print()\n",
        "\n",
        "def one_hot_encode(y):\n",
        "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
        "    for i, label in enumerate(y):\n",
        "        y_encoded[i, label - 1] = 1\n",
        "\n",
        "    return y_encoded\n",
        "\n",
        "def plot_roc_curve(prob_test_vec, y_test, labels):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    labels = labels\n",
        "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
        "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
        "        RocCurveDisplay.from_predictions(\n",
        "            y_test[:, senti],\n",
        "            prob_test_vec[:, senti],\n",
        "            name=f\"ROC curve for {labels[senti]}\",\n",
        "            color=color,\n",
        "            ax=ax,\n",
        "        )\n",
        "\n",
        "def calculate_OvR_roc_auc_score(model, x, y, x_test, y_test, labels): #average??\n",
        "    #y = one_hot_encode(y)\n",
        "    #y_test = one_hot_encode(y_test)\n",
        "\n",
        "    ovr_model = OneVsRestClassifier(model).fit(x, y)\n",
        "    prob_test_vec = ovr_model.predict_proba(x_test)\n",
        "\n",
        "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
        "    for _ in range(NUM_of_CLASSES):\n",
        "        fpr.append(0)\n",
        "        tpr.append(0)\n",
        "        thresholds.append(0)\n",
        "        auc_score.append(0)\n",
        "\n",
        "    for i in range(NUM_of_CLASSES):\n",
        "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
        "        auc_score[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    print(f\"AUC score: {auc_score}\")\n",
        "    averaged_auc_score = (sum(auc_score) / NUM_of_CLASSES)\n",
        "    print(f\"Averaged AUC score: {averaged_auc_score:.2f}\")\n",
        "\n",
        "    plot_roc_curve(prob_test_vec, y_test, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AlfBIR9a7QVm"
      },
      "outputs": [],
      "source": [
        "def plot_development(history):\n",
        "    acc =  history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title('Training and validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "j1oGW90j7QVm",
        "outputId": "99ba0c64-4044-4e52-b787-50acc4b43368"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(Dense(NUM_OUTPUT_CLASSES, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput_layer\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49msummary()\n\u001b[1;32m     11\u001b[0m basic_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_train_scores, y_train_encoded, validation_data\u001b[39m=\u001b[39m(x_val_scores, y_val_encoded), batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     13\u001b[0m accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test_scores, y_test_encoded)[\u001b[39m1\u001b[39m]\n",
            "File \u001b[0;32m/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py:3292\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3263\u001b[0m \n\u001b[1;32m   3264\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3289\u001b[0m \u001b[39m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3290\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m-> 3292\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3296\u001b[0m     )\n\u001b[1;32m   3297\u001b[0m layer_utils\u001b[39m.\u001b[39mprint_summary(\n\u001b[1;32m   3298\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3299\u001b[0m     line_length\u001b[39m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     layer_range\u001b[39m=\u001b[39mlayer_range,\n\u001b[1;32m   3305\u001b[0m )\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "# input layer is sequence of integers (words)\n",
        "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, name=\"embedding_layer\")) # part of input layer as it transforms integers into dense vectors, input shape = (None, MAX_SEQ_LEN)\n",
        "model.add(LSTM(64, name='hidden_layer')) # hidden layer\n",
        "model.add(Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output_layer\"))\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "basic_history = model.fit(x_train_scores, y_train_encoded, validation_data=(x_val_scores, y_val_encoded), batch_size=16, epochs=3)\n",
        "\n",
        "accuracy = model.evaluate(x_test_scores, y_test_encoded)[1]\n",
        "print(f\"Naive model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "del model\n",
        "\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fPrSGJ177QVn"
      },
      "source": [
        "## Hypterparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2CKvzLVM7QVn"
      },
      "outputs": [],
      "source": [
        "batch_size= 16\n",
        "epochs=30\n",
        "\n",
        "num_lstm_layersA = Integer(low=1, high=3, name='num_lstm_layersA')\n",
        "num_lstm_layersB = Integer(low=1, high=3, name='num_lstm_layersB')\n",
        "num_lstm_unitsA = Categorical([32, 64], name='num_lstm_unitsA')\n",
        "num_lstm_unitsB = Categorical([32, 64], name='num_lstm_unitsB')\n",
        "#learning_rate = Categorical([1e-2], name='learning_rate')\n",
        "#adam_decay = Categorical([1e-6, 1e-4, 1e-2], name=\"adam_decay\")\n",
        "\n",
        "search_space = [\n",
        "            num_lstm_layersA,\n",
        "            num_lstm_layersB,\n",
        "            num_lstm_unitsA,\n",
        "            num_lstm_unitsB,\n",
        "            ]\n",
        "\n",
        "# Specify one or more initial points for the search of optimal parameter\n",
        "default_params = [1,\n",
        "                  1,\n",
        "                  32,\n",
        "                  32,\n",
        "                  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KFAG6ZRP7QVn"
      },
      "outputs": [],
      "source": [
        "def define_multi_channel_lstm_model(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "     # SentiWordNet scores layer\n",
        "    inputsA = Input(shape=(MAX_SEQ_LEN, 1), name=\"input sentiwordnet scores\")\n",
        "\n",
        "    # Word2Vec embedding layer\n",
        "    inputsB = Input(shape=(MAX_SEQ_LEN,), name=\"input word2vec embeddings\")\n",
        "\n",
        "    # Define an embedding layer for each input\n",
        "    embeddingsB = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddingsB\")(inputsB)\n",
        "\n",
        "    # Pass both embeddings through their own LSTM layers\n",
        "    lstm_layersA = inputsA\n",
        "    for i in range(num_lstm_layersA):\n",
        "        nameA = 'layer_lstmA_{0}'.format(i+1)\n",
        "        if i < num_lstm_layersA-1:\n",
        "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=True, name=nameA)(lstm_layersA)\n",
        "        else:\n",
        "            lstm_layersA = LSTM(num_lstm_unitsA, return_sequences=False, name=nameA)(lstm_layersA)\n",
        "\n",
        "    lstm_layersB = embeddingsB\n",
        "    for i in range(num_lstm_layersB):\n",
        "        nameA = 'layer_lstmB_{0}'.format(i+1)\n",
        "        if i < num_lstm_layersB-1:\n",
        "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=True, name=nameA,)(lstm_layersB)\n",
        "        else:\n",
        "            lstm_layersB = LSTM(num_lstm_unitsB, return_sequences=False, name=nameA)(lstm_layersB)\n",
        "\n",
        "\n",
        "    # Concatenate the two inputs\n",
        "    merged = concatenate([lstm_layersA, lstm_layersB])\n",
        "\n",
        "    # Additional Dense layer for dimensionality reduction\n",
        "    dense_layer = Dense(16, activation='relu', name=\"dense_layer\")(merged)\n",
        "\n",
        "    # Dense layer for the merged inputs & output Layer\n",
        "    outputs = Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output\")(dense_layer)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[inputsA, inputsB], outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    rmsprop = RMSprop(learning_rate=0.01) # default is 0.001\n",
        "    model.compile(optimizer=rmsprop, loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RmZDNHqf7QVo"
      },
      "outputs": [],
      "source": [
        "@use_named_args(dimensions=search_space)\n",
        "def multi_objective_function(num_lstm_layersA, num_lstm_layersB, num_lstm_unitsA, num_lstm_unitsB):\n",
        "\n",
        "    model = define_multi_channel_lstm_model(num_lstm_layersA=num_lstm_layersA,\n",
        "                                            num_lstm_layersB=num_lstm_layersB,\n",
        "                                            num_lstm_unitsA=num_lstm_unitsA,\n",
        "                                            num_lstm_unitsB=num_lstm_unitsB,\n",
        "                                            )\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                        y_train_encoded,\n",
        "                        validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                        epochs=epochs, # TODO\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=2\n",
        "                        )\n",
        "    #return the validation accuracy for the last epoch.\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "    loss = history.history['val_loss'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Loss: {loss:.2}\\n\")\n",
        "\n",
        "\n",
        "    # Delete the Keras model with these hyper-parameters from memory.\n",
        "    del model\n",
        "\n",
        "    # Clear the Keras session, otherwise it will keep adding new\n",
        "    # models to the same TensorFlow graph each time we create\n",
        "    # a model with a different set of hyper-parameters.\n",
        "    K.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    # the optimizer aims for the lowest score, so we return our negative accuracy\n",
        "    return -accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R_jjoL_97QVo"
      },
      "source": [
        "## Gradient Boosted Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jev5XRL87QVp",
        "outputId": "315ba824-d7bc-40b2-fbdb-4746c757b4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input word2vec embeddings (Inp  [(None, 430)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " input sentiwordnet scores (Inp  [(None, 430, 1)]    0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 430, 100)     1135400     ['input word2vec embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 32)           4352        ['input sentiwordnet scores[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 32)           17024       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['layer_lstmA_1[0][0]',          \n",
            "                                                                  'layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 16)           1040        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            51          ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,157,867\n",
            "Trainable params: 22,467\n",
            "Non-trainable params: 1,135,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "2563/2563 - 97s - loss: 0.2106 - accuracy: 0.4872 - val_loss: 0.1409 - val_accuracy: 0.8674 - 97s/epoch - 38ms/step\n",
            "Epoch 2/30\n",
            "2563/2563 - 92s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1610 - val_accuracy: 0.8674 - 92s/epoch - 36ms/step\n",
            "Epoch 3/30\n",
            "2563/2563 - 93s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1556 - val_accuracy: 0.8674 - 93s/epoch - 36ms/step\n",
            "Epoch 4/30\n",
            "2563/2563 - 93s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1459 - val_accuracy: 0.8674 - 93s/epoch - 36ms/step\n",
            "Epoch 5/30\n",
            "2563/2563 - 93s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1506 - val_accuracy: 0.8674 - 93s/epoch - 36ms/step\n",
            "Epoch 6/30\n",
            "2563/2563 - 92s - loss: 0.2105 - accuracy: 0.4879 - val_loss: 0.1536 - val_accuracy: 0.8674 - 92s/epoch - 36ms/step\n",
            "Accuracy: 86.74%\n",
            "Loss: 0.15\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input word2vec embeddings (Inp  [(None, 430)]       0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " input sentiwordnet scores (Inp  [(None, 430, 1)]    0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " embeddingsB (Embedding)        (None, 430, 100)     1135400     ['input word2vec embeddings[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmA_1 (LSTM)           (None, 430, 32)      4352        ['input sentiwordnet scores[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " layer_lstmB_1 (LSTM)           (None, 430, 32)      17024       ['embeddingsB[0][0]']            \n",
            "                                                                                                  \n",
            " layer_lstmA_2 (LSTM)           (None, 430, 32)      8320        ['layer_lstmA_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmB_2 (LSTM)           (None, 430, 32)      8320        ['layer_lstmB_1[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmA_3 (LSTM)           (None, 32)           8320        ['layer_lstmA_2[0][0]']          \n",
            "                                                                                                  \n",
            " layer_lstmB_3 (LSTM)           (None, 32)           8320        ['layer_lstmB_2[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['layer_lstmA_3[0][0]',          \n",
            "                                                                  'layer_lstmB_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 16)           1040        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 3)            51          ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,191,147\n",
            "Trainable params: 55,747\n",
            "Non-trainable params: 1,135,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "2563/2563 - 286s - loss: 0.2110 - accuracy: 0.4870 - val_loss: 0.1573 - val_accuracy: 0.8674 - 286s/epoch - 112ms/step\n",
            "Epoch 2/30\n",
            "2563/2563 - 276s - loss: 0.2105 - accuracy: 0.4878 - val_loss: 0.1484 - val_accuracy: 0.8674 - 276s/epoch - 108ms/step\n",
            "Epoch 3/30\n",
            "2563/2563 - 277s - loss: 0.2105 - accuracy: 0.4878 - val_loss: 0.1567 - val_accuracy: 0.8674 - 277s/epoch - 108ms/step\n",
            "Epoch 4/30\n",
            "2563/2563 - 277s - loss: 0.2104 - accuracy: 0.4878 - val_loss: 0.1472 - val_accuracy: 0.8674 - 277s/epoch - 108ms/step\n",
            "Epoch 5/30\n",
            "2563/2563 - 277s - loss: 0.2105 - accuracy: 0.4878 - val_loss: 0.1633 - val_accuracy: 0.8674 - 277s/epoch - 108ms/step\n",
            "Epoch 6/30\n",
            "2563/2563 - 277s - loss: 0.2105 - accuracy: 0.4878 - val_loss: 0.1430 - val_accuracy: 0.8674 - 277s/epoch - 108ms/step\n",
            "Epoch 7/30\n"
          ]
        }
      ],
      "source": [
        "gbrt_result = gbrt_minimize(func=multi_objective_function,\n",
        "                            dimensions=search_space,\n",
        "                            n_calls=12,\n",
        "                            n_jobs=-1,\n",
        "                            x0=default_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q-VNfO97QVp"
      },
      "outputs": [],
      "source": [
        "# TODO data frame summarizing parameter search\n",
        "gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
        "print(\"Best Hyperparameters:\", gbrt_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56s8zsrp7QVp"
      },
      "outputs": [],
      "source": [
        "model = define_multi_channel_lstm_model(gbrt_best_params['num_lstm_layersA'],\n",
        "                                        gbrt_best_params['num_lstm_layersB'],\n",
        "                                        gbrt_best_params['num_lstm_unitsA'],\n",
        "                                        gbrt_best_params['num_lstm_unitsB'],\n",
        "                                        )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
        "history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                    y_train_encoded,\n",
        "                    validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                    epochs=epochs, # TODO\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=2\n",
        "                    )\n",
        "plot_development(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKiDO3b7QVq"
      },
      "outputs": [],
      "source": [
        "model.evaluate([x_train_encoded, x_train_encoded], y_train_encoded)\n",
        "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_val_encoded, x_val_encoded], y_val_encoded, verbose=0)\n",
        "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_test_encoded, x_test_encoded], y_test_encoded, verbose=0)\n",
        "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
        "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
        "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lV3bhP207QVq"
      },
      "source": [
        "## Gaussian Process Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa3SQnB27QVq"
      },
      "outputs": [],
      "source": [
        "gp_result = gp_minimize(func=multi_objective_function,\n",
        "                            dimensions=search_space,\n",
        "                            n_calls=12,\n",
        "                            noise= 0.01,\n",
        "                            n_jobs=-1,\n",
        "                            kappa = 5,\n",
        "                            x0=default_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-kn5R3u7QVr"
      },
      "outputs": [],
      "source": [
        "# TODO data frame summarizing parameter search\n",
        "gp_best_params = {param.name: value for param, value in zip(gp_result.space, gp_result.x)}\n",
        "print(\"Best Hyperparameters:\", gp_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUx6JBUX7QVr"
      },
      "outputs": [],
      "source": [
        "model = define_multi_channel_lstm_model(gp_best_params['num_lstm_layersA'],\n",
        "                                        gp_best_params['num_lstm_layersB'],\n",
        "                                        gp_best_params['num_lstm_unitsA'],\n",
        "                                        gp_best_params['num_lstm_unitsB'],\n",
        "                                        gp_best_params['learning_rate'],\n",
        "                                        gp_best_params['adam_decay']\n",
        "                                        )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # TODO: should I, again?\n",
        "history = model.fit([x_train_encoded, x_train_encoded],\n",
        "                    y_train_encoded,\n",
        "                    validation_data=([x_val_encoded, x_val_encoded], y_val_encoded),\n",
        "                    epochs=epochs, # TODO\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=2\n",
        "                    )\n",
        "plot_development(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puVch7RE7QVr"
      },
      "outputs": [],
      "source": [
        "model.evaluate([x_train_encoded, x_train_encoded], y_train_encoded)\n",
        "evaluate_model(model, \"Train multi-LSTM\", x_train_encoded, y_train_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_val_encoded, x_val_encoded], y_val_encoded, verbose=0)\n",
        "evaluate_model(model, \"Val multi-LSTM\", x_val_encoded, y_val_encoded, only_metrics=True)\n",
        "\n",
        "model.evaluate([x_test_encoded, x_test_encoded], y_test_encoded, verbose=0)\n",
        "evaluate_model(model, \"Test multi-LSTM\", x_test_encoded, y_test_encoded, y_test, only_metrics=False)\n",
        "senti_labels = ['negative', 'neutral', 'positive'] # TODO\n",
        "#calculate_OvR_roc_auc_score(model, x_train, y_train, x_test, y_test, senti_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
