{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekinfergan/Thesis_Jupyter_Final/blob/main/src/models/rnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A-Xt2ne4djh"
      },
      "source": [
        "# Deep Learning - LSTM & GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2ckCio4nE6",
        "outputId": "1cbfbea5-38a3-4cbe-c25a-044df8ce2993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thesis_Jupyter_Final'...\n",
            "remote: Enumerating objects: 1059, done.\u001b[K\n",
            "remote: Counting objects: 100% (479/479), done.\u001b[K\n",
            "remote: Compressing objects: 100% (307/307), done.\u001b[K\n",
            "remote: Total 1059 (delta 229), reused 404 (delta 168), pack-reused 580\u001b[K\n",
            "Receiving objects: 100% (1059/1059), 192.14 MiB | 28.48 MiB/s, done.\n",
            "Resolving deltas: 100% (547/547), done.\n",
            "Updating files: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ekinfergan/Thesis_Jupyter_Final.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm57pwr44ffU",
        "outputId": "e55728f1-b9a8-4a76-c405-fa34bac80cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis_Jupyter_Final\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd Thesis_Jupyter_Final\n",
        "!git pull\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZq9XZCv4yYu",
        "outputId": "9e9ac813-32df-4fd0-89b7-a0801ff6dd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-n75sf6n0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-n75sf6n0\n",
            "  Resolved https://github.com/scikit-optimize/scikit-optimize.git to commit a2369ddbc332d16d8ff173b12404b03fea472492\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize==0.9.0)\n",
            "  Using cached pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.9.0) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.0) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize==0.9.0) (3.1.0)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.0-py2.py3-none-any.whl size=100250 sha256=465514bcaa6f2f714c562abc8431175e093d98e5cf3cb2e06f582962f8149cef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o6qt2c41/wheels/2f/f0/ed/db529a96372d05bd34f6c3a2fa7c08ef7a8314315ac46e49d7\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PbAXzVr-4djj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from numpy import asarray\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from itertools import cycle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Input, Embedding, concatenate, Dense, LSTM, GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop, Adagrad\n",
        "\n",
        "import skopt\n",
        "from skopt import gbrt_minimize, gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import functools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OXWMoudx4djk",
        "outputId": "611bb178-be01-462d-a46e-83c4ac1bfe49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 24 23:42:00 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    47W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "# just checkıng gpu ıs avaılable\n",
        "\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EynHCpQ04djk",
        "outputId": "97e307a2-245f-43be-d6cb-ee667a925491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis_Jupyter_Final/src/\n"
          ]
        }
      ],
      "source": [
        "script_dir = os.path.dirname(os.path.abspath('mc_lstm-fix.ipynb'))\n",
        "data_path = os.path.join(script_dir, 'Thesis_Jupyter_Final/src/')\n",
        "os.getcwd()\n",
        "print(data_path)\n",
        "\n",
        "input_folder_path = os.path.join(data_path, 'input')\n",
        "processed_folder_path = os.path.join(data_path, 'input/processed/normal')\n",
        "results_folder_path =  os.path.join(data_path, \"results\")\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(results_folder_path):\n",
        "    os.makedirs(results_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FVinrA7E6ISQ"
      },
      "outputs": [],
      "source": [
        "senti_labels_dict = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
        "senti_labels_names = list(senti_labels_dict.values())\n",
        "senti_labels_nums = list(senti_labels_dict.keys())\n",
        "NUM_of_CLASSES = 3\n",
        "\n",
        "VOCAB_SIZE = 11395\n",
        "MAX_SEQ_LEN = 449\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_OUTPUT_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOIpxE654djm",
        "outputId": "e1822def-c6a7-4b1e-b988-148cb874d30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_encoded:\n",
            "[[  96  549  929 ...    0    0    0]\n",
            " [ 453  240 1125 ...    0    0    0]\n",
            " [1260   67  312 ...    0    0    0]\n",
            " [ 127 1352 6694 ...    0    0    0]\n",
            " [ 529   10   69 ...    0    0    0]]\n",
            "\n",
            "embedding vectors: [-0.57674998 -0.42304999  0.27188    -0.31986001  0.18842   ]...\n",
            "\n",
            "y_train_encoded:\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(os.path.join(processed_folder_path, \"train.csv\"))\n",
        "val = pd.read_csv(os.path.join(processed_folder_path, \"val.csv\"))\n",
        "test = pd.read_csv(os.path.join(processed_folder_path, \"test.csv\"))\n",
        "\n",
        "x_train = train['x']\n",
        "y_train = train['y']\n",
        "x_val = val['x']\n",
        "y_val = val['y']\n",
        "x_test = test['x']\n",
        "y_test = test['y']\n",
        "import pickle\n",
        "\n",
        "# Load encoded sequences\n",
        "with open(os.path.join(processed_folder_path, \"x_train_encoded.pkl\"), \"rb\") as f:\n",
        "    x_train_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_val_encoded.pkl\"), \"rb\") as f:\n",
        "    x_val_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"x_test_encoded.pkl\"), \"rb\") as f:\n",
        "    x_test_encoded = pickle.load(f)\n",
        "print(f\"x_train_encoded:\\n{x_train_encoded[:5]}\\n\")\n",
        "\n",
        "# Load embedding vectors\n",
        "with open(os.path.join(processed_folder_path, \"embedding_matrix.pkl\"), \"rb\") as f:\n",
        "    w2v_embedding_vectors = pickle.load(f)\n",
        "print(f\"embedding vectors: {w2v_embedding_vectors[10][:5]}...\\n\")\n",
        "\n",
        "# Load encoded labels\n",
        "with open(os.path.join(processed_folder_path, \"y_train_encoded.pkl\"), \"rb\") as f:\n",
        "    y_train_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"y_val_encoded.pkl\"), \"rb\") as f:\n",
        "    y_val_encoded = pickle.load(f)\n",
        "with open(os.path.join(processed_folder_path, \"y_test_encoded.pkl\"), \"rb\") as f:\n",
        "    y_test_encoded = pickle.load(f)\n",
        "print(f\"y_train_encoded:\\n{y_train_encoded[:5]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsJ4d-mY4djn"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7hXUlQ8t4djn"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(y):\n",
        "    y_encoded = np.zeros((len(y), NUM_of_CLASSES))\n",
        "    for i, label in enumerate(y):\n",
        "        y_encoded[i, label - 1] = 1\n",
        "\n",
        "    return y_encoded\n",
        "\n",
        "def calculate_classification_report(y, y_pred):\n",
        "    report = classification_report(y, y_pred, labels=senti_labels_nums, target_names=senti_labels_names)\n",
        "    return report\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, res_path):\n",
        "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
        "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat, display_labels=senti_labels_names)\n",
        "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
        "    plt.title(f'Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(res_path, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def plot_roc_curve(prob_test_vec, y_test, res_path):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    colors = cycle(['limegreen', 'dodgerblue', 'red'])\n",
        "    for senti, color in zip(range(NUM_of_CLASSES), colors):\n",
        "        RocCurveDisplay.from_predictions(\n",
        "            y_test[:, senti],\n",
        "            prob_test_vec[:, senti],\n",
        "            name=f\"ROC curve for {senti_labels_names[senti]}\",\n",
        "            color=color,\n",
        "            ax=ax,\n",
        "        )\n",
        "    plt.savefig(os.path.join(res_path, \"roc_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def calculate_OvR_roc_auc_score(model, model_name, x_test, y_test, res_path):\n",
        "    prob_test_vec = model.predict(x_test)\n",
        "\n",
        "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
        "    for _ in range(NUM_of_CLASSES):\n",
        "        fpr.append(0)\n",
        "        tpr.append(0)\n",
        "        thresholds.append(0)\n",
        "        auc_score.append(0)\n",
        "\n",
        "     # Determine class proportions which will be the weights for the average\n",
        "    lb = LabelBinarizer()\n",
        "    y_test_bin = lb.fit_transform(y_test)\n",
        "    class_proportions = y_test_bin.mean(axis=0)\n",
        "\n",
        "    for i in range(NUM_of_CLASSES):\n",
        "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], prob_test_vec[:, i])\n",
        "        auc_score[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    weighted_avg_auc_score = np.average(auc_score, weights=class_proportions)\n",
        "    # Save AUC to results.txt\n",
        "    with open(os.path.join(res_path, f\"{model_name}_results.txt\"), \"a\") as f:\n",
        "        auc_score_str = ', '.join(f'{score:.2f}' for score in auc_score)\n",
        "        f.write(f\"AUC score: [{auc_score_str}]\\n\")\n",
        "        f.write(f\"Weighted average AUC score: {weighted_avg_auc_score:.2f}\\n\")\n",
        "\n",
        "    plot_roc_curve(prob_test_vec, y_test, res_path)\n",
        "\n",
        "def get_results(y_pred, y, x, score, history, model, model_name, params, res_path):\n",
        "    if not os.path.exists(res_path):\n",
        "        os.makedirs(res_path)\n",
        "\n",
        "    # Convert to one hot vectors\n",
        "    y_classes = np.argmax(y, axis=1) + 1\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1) + 1\n",
        "\n",
        "    print(y_pred.shape)\n",
        "    print(y_classes.shape)\n",
        "    print(y_pred_classes.shape)\n",
        "\n",
        "    print(f\"Accuracy: {score[1]:.2%}\")\n",
        "    print(f\"Loss: {score[0]:.2f}\")\n",
        "\n",
        "    with open(os.path.join(res_path, f\"{model_name}_results.txt\"), \"w\") as f:\n",
        "        f.write(f\"*{model_name}\\n\")\n",
        "        f.write(f\"Optimizer Params: {params}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Accuracy: {score[1]:.2f}%\\n\")\n",
        "        f.write(f\"Loss: {score[0]:.2f}\\n\")\n",
        "\n",
        "        report = calculate_classification_report(y_classes, y_pred_classes)\n",
        "        if report is not None:\n",
        "            f.write(\"Classification Report:\\n\")\n",
        "            f.write(report)\n",
        "        else:\n",
        "            print(\"Failed to generate classification report\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        plot_confusion_matrix(y_classes, y_pred_classes, res_path)\n",
        "\n",
        "        # TODO:\n",
        "        calculate_OvR_roc_auc_score(model, model_name, x, y, res_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BE2Q4ObwwEpo"
      },
      "outputs": [],
      "source": [
        "def plot_development(history, model_name):\n",
        "    acc =  history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title(f\"{model_name} Training and Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title(f\"{model_name} Training and Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig(os.path.join(results_folder_path, f\"{model_name}_development_plot.png\"))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMO7Z6Bp4f9D"
      },
      "source": [
        "JUST CHECKING IF IT WORKS AT ALL WITH A SIMPLE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIxmyuQQ4b5q"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "# input layer is sequence of integers (words)\n",
        "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddings_layer\")) # part of input layer as it transforms integers into dense vectors, input shape = (None, MAX_SEQ_LEN)\n",
        "model.add(LSTM(64, name='hidden_layer')) # hidden layer\n",
        "model.add(Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output_layer\"))\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train_encoded, y_train_encoded, validation_data=(x_val_encoded, y_val_encoded), batch_size=16, epochs=1)\n",
        "\n",
        "y_pred = model.predict(x_test_encoded)\n",
        "score = model.evaluate(x_test_encoded, y_test_encoded)\n",
        "\n",
        "get_results(y_pred, y_test_encoded, x_test_encoded, score, history, model, \"LSTM\", model.optimizer.get_config(), results_folder_path)\n",
        "\n",
        "del model\n",
        "\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uryP_5tgwEpq"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "batch_size= 16\n",
        "epochs=1\n",
        "\n",
        "num_units = Categorical([32, 64, 128], name='num_units')\n",
        "learning_rate = Categorical([0.1, 1e-2], name='learning_rate')\n",
        "\n",
        "search_space = [\n",
        "            num_units,\n",
        "            learning_rate\n",
        "            ]\n",
        "\n",
        "# Specify one or more initial points for the search of optimal parameter\n",
        "default_params = [\n",
        "                  32,\n",
        "                  1e-2\n",
        "                  ]\n",
        "\n",
        "def define_model(num_units, learning_rate, layer_type):\n",
        "    # input layer\n",
        "    inputs = Input(shape=(MAX_SEQ_LEN,), name=\"input glove embeddings\")\n",
        "\n",
        "    # Define an embedding layer for the input\n",
        "    embeddings = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQ_LEN, weights=[w2v_embedding_vectors], trainable=False, name=\"embeddings\")(inputs)\n",
        "\n",
        "    # Pass embeddings through their own LSTM or GRU layers\n",
        "    layers = layer_type(num_units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, name=\"layer_1\")(embeddings)\n",
        "    layers = layer_type(num_units, dropout=0.2, recurrent_dropout=0.2, return_sequences=False, name=\"layer_2\")(layers)\n",
        "\n",
        "    # Dense layer for the merged inputs & output Layer\n",
        "    outputs = Dense(NUM_OUTPUT_CLASSES, activation='softmax', name=\"output\")(layers)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    rmsprop = RMSprop(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=rmsprop, loss='mean_squared_error', metrics=['accuracy']) # default learning rate = 0.001\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VH3zXV_N4djo"
      },
      "outputs": [],
      "source": [
        "def get_objective_function(layer_type):\n",
        "    @use_named_args(dimensions=search_space)\n",
        "    def objective_function(num_units, learning_rate):\n",
        "        model = define_model(num_units=num_units,\n",
        "                            learning_rate=learning_rate,\n",
        "                            layer_type=layer_type\n",
        "                            )\n",
        "\n",
        "        print(\"Optimization, starting training...\")\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        history = model.fit(x_train_encoded,\n",
        "                            y_train_encoded,\n",
        "                            validation_data=(x_val_encoded, y_val_encoded),\n",
        "                            epochs=epochs,\n",
        "                            batch_size=batch_size,\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=2\n",
        "                            )\n",
        "        print(\"Training Complete\")\n",
        "        # Return the validation accuracy for the last epoch.\n",
        "        accuracy = history.history['val_accuracy'][-1]\n",
        "        loss = history.history['val_loss'][-1]\n",
        "\n",
        "        # Print the classification accuracy.\n",
        "        print(f\"Accuracy: {accuracy:.2%}\")\n",
        "        print(f\"Loss: {loss:.2}\\n\")\n",
        "\n",
        "        del model,\n",
        "\n",
        "        print('Model deleted. Clearing session...')\n",
        "\n",
        "        # Clear the session.\n",
        "        K.clear_session()\n",
        "        tf.compat.v1.reset_default_graph()\n",
        "\n",
        "        # The optimizer aims for the lowest score, so we return our negative accuracy.\n",
        "        return -accuracy\n",
        "\n",
        "    return objective_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pBlA5cDzwEpr"
      },
      "outputs": [],
      "source": [
        "def perform_bayesian_opt(objective_function):\n",
        "    # Perform Bayesian Optimization\n",
        "    gbrt_result = gbrt_minimize(func=objective_function,\n",
        "                                dimensions=search_space,\n",
        "                                n_calls=12,\n",
        "                                n_jobs=-1,\n",
        "                                x0=default_params)\n",
        "\n",
        "    gbrt_best_params = {param.name: value for param, value in zip(gbrt_result.space, gbrt_result.x)}\n",
        "    print(\"Best Hyperparameters:\", gbrt_best_params)\n",
        "    print()\n",
        "\n",
        "    return gbrt_best_params\n",
        "\n",
        "def fit_model(model, model_name, x_train, y_train, x_val, y_val):\n",
        "    model_file = f\"model_{model_name}.h5\"\n",
        "    model_path = os.path.join(results_folder_path, model_file)\n",
        "\n",
        "    # Check if the model exists\n",
        "    if os.path.exists(model_path):\n",
        "        # If the model exists, then load it\n",
        "        model = load_model(model_path)\n",
        "        print(f\"Model {model_name} loaded successfully\")\n",
        "    else:\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        history = model.fit(x_train,\n",
        "                            y_train,\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            epochs=2,\n",
        "                            batch_size=batch_size,\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=2)\n",
        "\n",
        "        model.save(model_path)\n",
        "        print(f\"Model {model_name} saved at {model_path}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def init_results(model, model_name, x_train, y_train, x_val, y_val, x_test, y_test):\n",
        "    subfolder_path = f\"{model_name}_results\"\n",
        "    res_path = os.path.join(results_folder_path, subfolder_path)\n",
        "\n",
        "    y_pred = model.predict(x_train)\n",
        "    score = model.evaluate(x_train, y_train)\n",
        "    get_results(y_pred, y_train, x_train, score, model, f\"Train {model_name}\", model.optimizer.get_config(), res_path)\n",
        "\n",
        "    y_pred = model.predict(x_val)\n",
        "    score = model.evaluate(x_val, y_val)\n",
        "    get_results(y_pred, y_val, x_val, score, model, f\"Val {model_name}\", model.optimizer.get_config(), res_path)\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "    score = model.evaluate(x_test, y_test)\n",
        "    get_results(y_pred, y_test, x_test, score, model, f\"Test {model_name}\", model.optimizer.get_config(), res_path)\n",
        "\n",
        "\n",
        "def setup_dl(model_name):\n",
        "    if model_name == \"LSTM\":\n",
        "        objective_function = get_objective_function(LSTM)\n",
        "    else:\n",
        "        objective_function = get_objective_function(GRU)\n",
        "\n",
        "    best_params = perform_bayesian_opt(objective_function)\n",
        "\n",
        "    # Fit best model\n",
        "    model = define_model(best_params['num_units'],\n",
        "                         best_params['learning_rate'],\n",
        "                         LSTM if model_name == \"LSTM\" else GRU)\n",
        "\n",
        "\n",
        "    best_model, history = fit_model(model, model_name, x_train_encoded, y_train_encoded, x_val_encoded, y_val_encoded)\n",
        "\n",
        "    # Get results\n",
        "    plot_development(history, model_name)\n",
        "    init_results(best_model, model_name, x_train_encoded, y_train_encoded, x_val_encoded, y_val_encoded, x_test_encoded, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WdwlQpA1wEps",
        "outputId": "278a03c9-48e6-4f50-e0fe-034878971136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-26528c7d39c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msetup_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-9514eefb3e91>\u001b[0m in \u001b[0;36msetup_dl\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mobjective_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_bayesian_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Fit best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9514eefb3e91>\u001b[0m in \u001b[0;36mperform_bayesian_opt\u001b[0;34m(objective_function)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_bayesian_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Perform Bayesian Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     gbrt_result = gbrt_minimize(func=objective_function,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                 \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gbrt.py\u001b[0m in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m         base_estimator = cook_estimator(\"GBRT\", random_state=rng,\n\u001b[1;32m    178\u001b[0m                                         n_jobs=n_jobs)\n\u001b[0;32m--> 179\u001b[0;31m     return base_minimize(func, dimensions, base_estimator,\n\u001b[0m\u001b[1;32m    180\u001b[0m                          \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                          \u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random_starts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dims\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         raise RuntimeError(\"Optimization space (%s) and initial points in x0 \"\n\u001b[0m\u001b[1;32m    267\u001b[0m                            \"use inconsistent dimensions.\" % optimizer.space)\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# check callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Optimization space (Space([Categorical(categories=(32, 64, 128), prior=None),\n       Categorical(categories=(0.1, 0.01), prior=None)])) and initial points in x0 use inconsistent dimensions."
          ]
        }
      ],
      "source": [
        "setup_dl(\"LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAnajPUgwEps"
      },
      "outputs": [],
      "source": [
        "setup_dl(\"GRU\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}