{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b6a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea063ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = ['Id', 'Review', 'Sentiment']\n",
    "# Define a dictionary to map sentiment values to category names\n",
    "sentiment_labels = {1: 'Negative', 2: 'Neutral', 3: 'Positive'}\n",
    "NUM_of_CLASSES = 3\n",
    "\n",
    "\n",
    "# PROCESSING\n",
    "MIN_FREQ = 2\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7a0eb01",
   "metadata": {},
   "source": [
    "Goal of project: \n",
    "\n",
    "This notebook includes: (steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5416c0b",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "First, we load and explore the dataset and apply some initial processing such as setting the '*Id*' column as index and removing any empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1152d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing(data):\n",
    "    # Remove any rows with missing values and reset the index\n",
    "    data.replace('', np.nan, inplace=True)\n",
    "    data = data.dropna()\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97b6f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Review     10000 non-null  object\n",
      " 1   Sentiment  10000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n",
      "None\n",
      "\n",
      "Dataset shape: (10000, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good and interesting</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great course - I recommend it for all, especia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>One of the most useful course on IT Management!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was disappointed because the name is mislead...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Super content. I'll definitely re-do the course</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>One of the excellent courses at Coursera for i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                               good and interesting          3\n",
       "1  This class is very helpful to me. Currently, I...          3\n",
       "2  like!Prof and TAs are helpful and the discussi...          3\n",
       "3  Easy to follow and includes a lot basic and im...          3\n",
       "4  Really nice teacher!I could got the point eazl...          3\n",
       "5  Great course - I recommend it for all, especia...          3\n",
       "6    One of the most useful course on IT Management!          3\n",
       "7  I was disappointed because the name is mislead...          2\n",
       "8    Super content. I'll definitely re-do the course          3\n",
       "9  One of the excellent courses at Coursera for i...          3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "input_folder_path = \"./pls/Thesis_Jupyter_Final/input/\"\n",
    "data_filename = \"reviews_data.csv\"\n",
    "data_file_path = os.path.join(input_folder_path, data_filename)\n",
    "\n",
    "df_raw = pd.read_csv(data_file_path)\n",
    "df_raw = df_raw[:10000]\n",
    "\n",
    "# Set ID as index\n",
    "df_raw.set_index('Id', inplace=True, drop=True)\n",
    "\n",
    "# Remove NaN rows, before cleaning text\n",
    "df_raw = drop_missing(df_raw)\n",
    "\n",
    "# Create a copy of the original DataFrame to preserve the original data\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(df_raw.info())\n",
    "print(f'\\nDataset shape: {df_raw.shape}\\n')\n",
    "df_raw.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "622a91fc",
   "metadata": {},
   "source": [
    "### Analysing Data (TODO)\n",
    "We then analyse the dataset by observing the distribution of review per sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb16161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (Positive): 8917 reviews\n",
      "1 (Negative): 588 reviews\n",
      "2 (Neutral): 495 reviews\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of reviews per sentiment\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "\n",
    "# Print the counts for each category\n",
    "for sentiment_value, count in sentiment_counts.items():\n",
    "    sentiment_name = sentiment_labels[sentiment_value]\n",
    "    print(f\"{sentiment_value} ({sentiment_name}): {count} reviews\")\n",
    "\n",
    "# Define labels and colors for the pie chart\n",
    "labels = ['Positive', 'Neutral', 'Negative']\n",
    "colors = ['limegreen', 'dodgerblue', 'red']\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.pie(sentiment_counts, colors=colors, autopct='%1.1f%%',  pctdistance=0.8, textprops={'fontsize': 10, 'color': 'black'}, startangle=90)\n",
    "plt.axis('equal')  # pie as a circle\n",
    "plt.legend(labels=labels, loc='lower left')\n",
    "plt.title('Distribution of Reviews per Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc1bd547",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "675d3d0f",
   "metadata": {},
   "source": [
    "Next, we clean the data applying the following techniques (TODO: add info):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7094e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize.casual import EMOTICON_RE\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('words')\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3edfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning\n",
    "#english_words = set(nltk.corpus.words.words())\n",
    "emojis = [\n",
    "        #HAPPY\n",
    "        \":-)\",\n",
    "        \":)\",\n",
    "        \";)\",\n",
    "        \":o)\",\n",
    "        \":]\",\n",
    "        \":3\",\n",
    "        \":c)\",\n",
    "        \":>\",\n",
    "        \"=]\",\n",
    "        \"8)\",\n",
    "        \"=)\",\n",
    "        \":}\",\n",
    "        \":^)\",\n",
    "        \":-D\",\n",
    "        \":D\",\n",
    "        \"8-D\",\n",
    "        \"8D\",\n",
    "        \"x-D\",\n",
    "        \"xD\",\n",
    "        \"X-D\",\n",
    "        \"XD\",\n",
    "        \"=-D\",\n",
    "        \"=D\",\n",
    "        \"=-3\",\n",
    "        \"=3\",\n",
    "        \":-))\",\n",
    "        \":'-)\",\n",
    "        \":')\",\n",
    "        \":*\",\n",
    "        \":^*\",\n",
    "        \">:P\",\n",
    "        \":-P\",\n",
    "        \":P\",\n",
    "        \"X-P\",\n",
    "        \"x-p\",\n",
    "        \"xp\",\n",
    "        \"XP\",\n",
    "        \":-p\",\n",
    "        \":p\",\n",
    "        \"=p\",\n",
    "        \":-b\",\n",
    "        \":b\",\n",
    "        \">:)\",\n",
    "        \">;)\",\n",
    "        \">:-)\",\n",
    "        \"<3\",\n",
    "        # SAD\n",
    "        \":L\",\n",
    "        \":-/\",\n",
    "        \">:/\",\n",
    "        \":S\",\n",
    "        \">:[\",\n",
    "        \":@\",\n",
    "        \":-(\",\n",
    "        \":[\",\n",
    "        \":-||\",\n",
    "        \"=L\",\n",
    "        \":<\",\n",
    "        \":-[\",\n",
    "        \":-<\",\n",
    "        \"=\\\\\",\n",
    "        \"=/\",\n",
    "        \">:(\",\n",
    "        \":(\",\n",
    "        \">.<\",\n",
    "        \":'-(\",\n",
    "        \":'(\",\n",
    "        \":\\\\\",\n",
    "        \":-c\",\n",
    "        \":c\",\n",
    "        \":{\",\n",
    "        \">:\\\\\",\n",
    "        \";(\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1f5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Lowercase\n",
    "df['Review'] = df['Review'].str.lower()\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Replace contractions with their standard full forms\n",
    "contraction_mapping = {\n",
    "        \"isn't\": \"is not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        }\n",
    "\n",
    "for contraction, standard in contraction_mapping.items():\n",
    "    df['Review'] = df['Review'].str.replace(contraction, standard)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Remove punctuation in between words e.g. \"course.sometimes\" \n",
    "# and replace with space\n",
    "pattern = r'(?<=\\w)[^\\w\\s]+(?=\\w)'\n",
    "df['Review'] = df['Review'].str.replace(pattern, ' ')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Tokenize text into individual words (removes all extra spaces \\s)\n",
    "tokenizer = TweetTokenizer()\n",
    "df['Review'] = df['Review'].apply(tokenizer.tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05647ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Remove punctuation first in between words (typo),\n",
    "# and then all punctuation and numerals except for tokenized emojis\n",
    "pattern = r\"[^\\w\\s\" + \"\".join(re.escape(e) for e in emojis + list(emoji.EMOJI_DATA.keys())) + \"]|[\\d]+\" # match non-emoji special characters\n",
    "df['Review'] = df['Review'].apply(lambda tokens: [token for token in tokens if not re.match(pattern, token)])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Remove single characters\n",
    "df['Review'] = df['Review'].apply(lambda tokens: [word for word in tokens if len(word) > 1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Correct Spelling\n",
    "# Note: also removes '...' that was not removed before\n",
    "def correct_spelling(tokens):\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in emojis or token in emoji.EMOJI_DATA.keys():\n",
    "            corrected_tokens.append(token)  # If token is an emoji, add it to the corrected tokens\n",
    "        else:\n",
    "            corrected_token = spell_checker.correction(token)\n",
    "            if corrected_token is not None:\n",
    "                corrected_tokens.append(corrected_token)\n",
    "                \n",
    "    return corrected_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_checker = SpellChecker()\n",
    "df['Review'] = df['Review'].apply(correct_spelling)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db373fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: note to self (to be added to word-doc): If you check token by token, it also removes english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Perform negation tagging\n",
    "df['Review'] = df['Review'].apply(mark_negation)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fce956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Remove stopwords --> also removes words like 'not'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Review'] = df['Review'].apply(lambda tokens: [token for token in tokens if token not in stop_words])\n",
    "df['Review'] = df['Review'].apply(lambda tokens: [token for token in tokens if token.split('_')[0] not in stop_words])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: also lemmatize word removing _NEG\n",
    "# 10) Lemmatize words using WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Review'] = df['Review'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preprocessed tokens back to string\n",
    "df['Review'] = df['Review'].apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25434a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape before: {df_raw.shape}')\n",
    "print(f'Shape after preprocessing, before removing empty rows: {df.shape}')\n",
    "\n",
    "# Remove NaN rows, after cleaning text\n",
    "df = drop_missing(df) \n",
    "print(f'Shape after preprocessing, after removing empty rows: {df.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filename = \"cleaned_data.csv\"\n",
    "data_file_path = os.path.join(input_folder_path, cleaned_data_filename)\n",
    "df.to_csv(data_file_path, sep=',', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create word clouds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f18328f",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pickle\n",
    "from numpy import asarray\n",
    "import gensim.downloader as api\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f65f114",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f09fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'],\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "# Split the training dataset further into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Distribution:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(len(x_train), len(x_val), len(x_test)))\n",
    "print(f\"x_train: {x_train.head()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceb8e8d3",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b30607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words to create vocabulary\n",
    "word_counter = Counter()\n",
    "for review in x_train:\n",
    "    word_counter.update(review.split())\n",
    "\n",
    "print(word_counter.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vocabulary by removing words with frequency less than a set minimum frequency\n",
    "vocab = [word for word, count in word_counter.items() if count >= MIN_FREQ]\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocabulary size of {} reduced to {}.\\n\".format(len(word_counter), vocab_size))\n",
    "print(\"Vocabulary (first 50 tokens):\\n{}\".format(vocab[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folder_path = \"./pls/Thesis_Jupyter_Final/processed\"\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(processed_folder_path):\n",
    "    os.makedirs(processed_folder_path)\n",
    "\n",
    "vocab_filename = 'vocab.txt'\n",
    "file_path = os.path.join(processed_folder_path, vocab_filename)\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write('\\n'.join(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83fc4550",
   "metadata": {},
   "source": [
    "### Filter data with vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_filter_dataset(docs, filename, vocab):\n",
    "    filtered_dataset = []\n",
    "    for doc in docs:\n",
    "        filtered_text = ' '.join([word for word in doc.split() if word in vocab])\n",
    "        filtered_dataset.append(filtered_text)\n",
    "\n",
    "    # Save filtered dataset to a txt file\n",
    "    filtered_filename = f'filtered_{str(filename)}.txt'\n",
    "    file_path = os.path.join(processed_folder_path, filtered_filename)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(filtered_dataset))\n",
    "\n",
    "    # Convert the processed documents back to pandas.Series\n",
    "    filtered_dataset = pd.Series(filtered_dataset, index=docs.index)\n",
    "\n",
    "    # Convert empty rows to '<empty>'\n",
    "    placeholder = \"<empty>\"\n",
    "    filtered_dataset.replace('', placeholder, inplace=True)\n",
    "    \n",
    "    # Count the number of rows with '<empty>' #TODO: remove empty rows\n",
    "    num_empty_rows = filtered_dataset.str.count('<empty>').sum()\n",
    "    print(f'Number of rows with <empty> for {filename}: {num_empty_rows}')\n",
    "\n",
    "    # TODO: instead of saving, print?\n",
    "    # Save filled dataset to a txt file\n",
    "    filled_filename = f'filled_{str(filename)}.txt'\n",
    "    file_path = os.path.join(processed_folder_path, filled_filename)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(filtered_dataset))\n",
    "    \n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136714f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter dataset based on vocabulary\n",
    "x_train = freq_filter_dataset(x_train, \"x_train\", vocab)\n",
    "x_val = freq_filter_dataset(x_val, \"x_val\", vocab)\n",
    "x_test = freq_filter_dataset(x_test, \"x_test\", vocab)\n",
    "\n",
    "print(\"\\nData Distribution:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(len(x_train), len(x_val), len(x_test)))\n",
    "print(f\"x_train - updated: {x_train.head()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8c6d509",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS \n",
    "\n",
    "# TF-IDF\n",
    "MAX_FEATURES = 10000\n",
    "MAX_DF = 0.95\n",
    "MIN_DF = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccee997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer with the filtered vocabulary\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=MAX_FEATURES, # maximum number of features to keep, check unique vocabs and determine based on that, high causes saprse metrics and low value causes loss in important words/vocab\n",
    "    vocabulary=vocab,\n",
    "    lowercase=False,\n",
    "    ngram_range=(1, 1),  # range of n-grams, only unigrams now\n",
    "    max_df=MAX_DF,  # ignore terms that have a document frequency strictly higher than the threshold\n",
    "    min_df=MIN_DF,  # ignore terms that have a document frequency strictly lower than the threshold.\n",
    "    use_idf=True,  # enable IDF weighting\n",
    "    smooth_idf=True,  # smooth IDF weights --> provides stability, reduces run time errors\n",
    "    sublinear_tf=True  # apply sublinear scaling to term frequencies\n",
    ")\n",
    "\n",
    "# Fit and transform the training set\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Transform the validation and testing set\n",
    "x_val_tfidf = tfidf_vectorizer.transform(x_val)\n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afdbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tfidf_data(data, data_name, feature_names):\n",
    "    # Save the matrix with feature names as a DataFrame\n",
    "    data = pd.DataFrame(data.toarray(), columns=feature_names)\n",
    "    tfidf_filename = f'{data_name}.csv'\n",
    "    file_path = os.path.join(processed_folder_path, tfidf_filename)\n",
    "    data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d62af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Save vectorized data\n",
    "save_tfidf_data(x_train_tfidf, \"train_tfidf\", feature_names)\n",
    "save_tfidf_data(x_train_tfidf, \"val_tfidf\", feature_names)\n",
    "save_tfidf_data(x_test_tfidf, \"test_tfidf\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Given vocabulary-size : {},\".format(vocab_size))\n",
    "print(\"\\nData Shape:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(x_train_tfidf.shape, x_val_tfidf.shape, x_test_tfidf.shape))\n",
    "print(\"x_train_tfidf:\\n{}\".format(x_train_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nData Types:\\nx_train_tfidf - type: {type(x_train_tfidf)}\\nx_val_tfidf - type: {type(x_val_tfidf)}\\ny-train - type: {type(y_train)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca1595c",
   "metadata": {},
   "source": [
    "# Classical ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, RocCurveDisplay, confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "# TODO: why is it not sensible to use early stopping again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c72e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # TODO: not anymore?? Handle the zero-division error when there are no predicted samples for a label\n",
    "    # only interested in labels that were predicted at least once\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"*{model_name}\")\n",
    "    print(f\"Accuracy: {(accuracy * 100):.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"f1-score: {f1:.2f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_report(y_true, y_pred):\n",
    "    # Calculate classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeea9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_name, res_file_path, params, accuracy, precision, recall, f1_score, auc_score=None, report=None, only_metrics=False):\n",
    "    with open(res_file_path, 'a') as file:\n",
    "        file.write(f\"*{model_name}---->{params}\\n\")\n",
    "        file.write(f\"Accuracy: {(accuracy * 100):.2f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.2f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.2f}\\n\")\n",
    "        file.write(f\"f1-score: {f1_score:.2f}\\n\")\n",
    "\n",
    "        if not only_metrics:\n",
    "            file.write(f\"auc-score: {auc_score:.2f}\\n\\n\")\n",
    "            file.write(f\"{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30335352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, model_name, file_path):\n",
    "    cnf_mat = confusion_matrix(y_true, y_pred)\n",
    "    mat_disp = ConfusionMatrixDisplay(confusion_matrix=cnf_mat,\n",
    "                              display_labels=labels)\n",
    "    \n",
    "    mat_disp = mat_disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
    "    plt.title(f'Confusion Matrix {model_name}')\n",
    "    plt.savefig(file_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def plot(history, save_dir, model_name):\n",
    "    accuracy_plot = f'{save_dir}/{model_name}_plot.png'\n",
    "    loss_plot = f'{save_dir}/{model_name}_loss_plot.png'\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    #val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'r', label='Training acc')\n",
    "    #plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n",
    "\n",
    "    plt.title(f'{model_name} Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(save_dir)\n",
    "    plt.close()\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r', label='Training acc')\n",
    "    #plt.plot(epochs, val_loss, 'b', label='Validation acc')\n",
    "\n",
    "    plt.title(f'{model_name} Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(save_dir)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: can I use for svm?\n",
    "def plot_feature_imp(model, file_path):\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    feature_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    feature_importances.nlargest(20).plot.bar(ax=ax)\n",
    "    ax.set_title(\"Top 20 Most Predictive Features\")\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Importance')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OvR_roc_auc_score(model, x, y, labels): #average??\n",
    "    model = OneVsRestClassifier(model)\n",
    "    prob_test_vec = model.predict_proba(x)\n",
    "    \n",
    "    fpr, tpr, thresholds, auc_score = [], [], [], []\n",
    "    for _ in range(NUM_of_CLASSES):\n",
    "        fpr.append(0)\n",
    "        tpr.append(0)\n",
    "        thresholds.append(0)\n",
    "        auc_score.append(0)\n",
    "    \n",
    "    for i in range(NUM_of_CLASSES):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(y[:, i],\n",
    "                                                prob_test_vec[:, i])\n",
    "        auc_score[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return auc_score, prob_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf59084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(prob_test_vec, y, labels):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    labels = labels\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for class_id, color in zip(range(NUM_of_CLASSES), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y[:, class_id],\n",
    "            prob_test_vec[:, class_id],\n",
    "            name=f\"ROC curve for {labels[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, x, y_true, params, results_filename, only_metrics):\n",
    "    results_folder_path = \"./pls/Thesis_Jupyter_Final/results\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(results_folder_path):\n",
    "        os.makedirs(results_folder_path)\n",
    "    res_file_path = os.path.join(results_folder_path, results_filename + \".txt\")\n",
    "    \n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    # Calculate and save metrics\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_true, y_pred, model_name)\n",
    "    print(f\"Params: {params}\\n\")\n",
    "    senti_labels = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    if not only_metrics:\n",
    "        # Calculate OvR AUC ROC score\n",
    "        auc_score, prob_test_vec = calculate_OvR_roc_auc_score(model, x, y_true, senti_labels)\n",
    "        plot_roc_curve(prob_test_vec, y_true, labels)\n",
    "        # Calculate classification report\n",
    "        report = calculate_classification_report(y_true, y_pred)\n",
    "    \n",
    "        # Plot confusion matrix\n",
    "        cnf_res_file_path = os.path.join(results_folder_path, f\"{results_filename}_cnf.png\")\n",
    "        plot_confusion_matrix(y_test, y_pred, senti_labels, model_name, cnf_res_file_path)\n",
    "\n",
    "         # Plot accuracy # TODO?\n",
    "        #plot(history, model_name)\n",
    "        f_imp_res_file_path = os.path.join(results_folder_path, f\"{results_filename}_feat_imp.png\")\n",
    "        plot_feature_imp(model, f_imp_res_file_path) # for especially RF\n",
    "        \n",
    "    save_results(model_name, res_file_path, params, accuracy, precision, recall, f1, auc_score, report, only_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10848f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top3_models(top3_models):    \n",
    "    # Print the sorted list of mean test scores and standard deviation of test scores\n",
    "    print(\"\\nTop 3 parameter combinations ranked by performance (from best to worst):\")\n",
    "    for index, row in top3_models.iterrows():\n",
    "        mean_score = row['mean_test_score']\n",
    "        std_score = row['std_test_score']\n",
    "        params = row['params']\n",
    "        print(f\"Mean Test Score: {mean_score:.4f} (±{std_score:.4f}) for {params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b616c18",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6e69ba1",
   "metadata": {},
   "source": [
    "### Training & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the Random Forest model\n",
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be257e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    #'max_features': ['auto', 'sqrt'],  # Number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=rf_param_grid, cv=5)\n",
    "grid_search.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Get the mean test scores and standard deviations of test scores for all parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_results = results_df.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "top3_models = sorted_results[:5] # TODO: update to 3\n",
    "print_top3_models(top3_models)\n",
    "\n",
    "top3_models = sorted_results[:3] # TODO: and delete this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "159c13c0",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26126294",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d1f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_params = top3_models['params'].values\n",
    "res_filename = \"rf_results\"\n",
    "\n",
    "# Evaluate the top 3 models on the validation set\n",
    "rf_cand_0 = RandomForestClassifier(**top3_params[0])\n",
    "rf_cand_0.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_0, \"Training-RF-0\", x_train_tfidf, y_train, top3_params[0], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_0, \"Validation-RF-0\", x_val_tfidf, y_val, top3_params[0], res_filename, only_metrics=True)\n",
    "\n",
    "rf_cand_1 = RandomForestClassifier(**top3_params[1])\n",
    "rf_cand_1.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_1, \"Training-RF-1\", x_train_tfidf, y_train, top3_params[1], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_1, \"Validation-RF-1\", x_val_tfidf, y_val, top3_params[1], res_filename, only_metrics=True)\n",
    "\n",
    "rf_cand_2 = RandomForestClassifier(**top3_params[2])\n",
    "rf_cand_2.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_2, \"Training-RF-2\", x_train_tfidf, y_train, top3_params[2], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_2, \"Validation-RF-2\", x_val_tfidf, y_val, top3_params[2], res_filename, only_metrics=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdaaf668",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best model and evaluate the models on the test data #TODO\n",
    "rf_best = rf_cand_0\n",
    "y_pred = rf_best.predict(x_test_tfidf)\n",
    "evaluate_model(rf_best, \"RF-best\", x_test_tfidf, y_test, rf_best.get_params(), res_filename, only_metrics=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1790120",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "214966ae",
   "metadata": {},
   "source": [
    "### Training & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the Naive Bayes model & fit on training data\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with TF-IDF vectorizer and multinomial Naive Bayes classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),  # Replace tfidf_vectorizer with your existing TF-IDF vectorizer\n",
    "    ('nb_clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "nb_param_grid = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],  # Maximum number of features\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Range of n-grams\n",
    "    'nb_clf__alpha': [0.1, 0.5, 1.0],  # Smoothing parameter for MultinomialNB\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"type of x_train_tfidf: \", type(x_train_tfidf))\n",
    "print(\"type of x_train_tfidf: \", type(y_train))\n",
    "print(\"shape of x_train_tfidf: \", x_train_tfidf.shape)\n",
    "print(\"shape of x_train_tfidf: \", y_train.shape)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=nb_param_grid, cv=5, error_score='raise')\n",
    "grid_search.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Get the best parameters and best score from grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "\n",
    "# Get the mean test scores and standard deviations of test scores for all parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_results = results_df.sort_values(by='mean_test_score', ascending=False)\n",
    "top3_models = sorted_results[:5] # TODO: update 10 to 3\n",
    "print_top3_models(top3_models)\n",
    "top3_models = sorted_results[:3] # TODO: and delete this\n",
    "top3_params = top3_models['params'].values\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae5d8b7",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dd270a0",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d223208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d7f0cd9",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bad5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3287aee",
   "metadata": {},
   "source": [
    "## 3. SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f34d76f",
   "metadata": {},
   "source": [
    "### Training &  Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the SVM model\n",
    "svm_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': [0.1, 1, 'scale']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(svm_model, param_grid=svm_param_grid, cv=5)\n",
    "grid_search.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Get the mean test scores and standard deviations of test scores for all parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_results = results_df.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "top3_models = sorted_results[:5] # TODO: update to 3\n",
    "print_top3_models(top3_models)\n",
    "\n",
    "top3_models = sorted_results[:3] # TODO: and delete this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceb654f8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "525c68dd",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4da28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top3_params = top3_models['params'].values\n",
    "res_filename = \"svm_results.txt\"\n",
    "\n",
    "# Evaluate the top 3 models on the validation set\n",
    "svm_cand_0 = SVC(**top3_params[0])\n",
    "svm_cand_0.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_0, \"Training-SVM-0\", x_train_tfidf, y_train, top3_params[0], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_0, \"Validation-SVM-0\", x_val_tfidf, y_val, top3_params[0], res_filename, only_metrics=True)\n",
    "\n",
    "svm_cand_1 = SVC(**top3_params[1])\n",
    "svm_cand_1.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_1, \"Training-SVM-1\", x_train_tfidf, y_train, top3_params[1], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_1, \"Validation-SVM-1\", x_val_tfidf, y_val, top3_params[1], res_filename, only_metrics=True)\n",
    "\n",
    "\n",
    "svm_cand_2 = SVC(**top3_params[2])\n",
    "svm_cand_2.fit(x_train_tfidf, y_train)\n",
    "evaluate_model(rf_cand_2, \"Training-SVM-2\", x_train_tfidf, y_train, top3_params[2], res_filename, only_metrics=True)\n",
    "evaluate_model(rf_cand_2, \"Validation-SVM-2\", x_val_tfidf, y_val, top3_params[2], res_filename, only_metrics=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0071c488",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best model and evaluate the models on the test data #TODO\n",
    "svm_best = svm_cand_0\n",
    "y_pred = svm_best.predict(x_test_tfidf)\n",
    "evaluate_model(rf_best, \"SVM-best\", x_test_tfidf, y_test, rf_best.get_params(), res_filename, only_metrics=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9982ae27",
   "metadata": {},
   "source": [
    "# Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d99acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find maximum sequence length\n",
    "max_seq_length = max([len(doc.split()) for doc in x_train])\n",
    "print(f'\\nMaximum review length: {max_seq_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tokenizer (on training data)\n",
    "tokenizer = Tokenizer()\n",
    "# Remove default filters, including punctuation\n",
    "tokenizer.filters = \"\"  \n",
    "# Disable lowercase conversion\n",
    "tokenizer.lower = False  \n",
    "tokenizer.fit_on_texts(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb76b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(lines, tokenizer, max_length):\n",
    "    # Integer encode\n",
    "    encoded_seq = tokenizer.texts_to_sequences(lines)\n",
    "    # Pad the encoded sequences\n",
    "    padded = pad_sequences(encoded_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data\n",
    "x_train_encoded = encode_text(x_train, tokenizer, max_seq_length)\n",
    "x_val_encoded = encode_text(x_val, tokenizer, max_seq_length)\n",
    "x_test_encoded = encode_text(x_test, tokenizer, max_seq_length)\n",
    "\n",
    "print(\"Encoded-data shapes:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(x_train_encoded.shape, x_val_encoded.shape, x_test_encoded.shape))\n",
    "print(f\"x_train_encoded[:3]:\\n{x_val_encoded[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure labels\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values\n",
    "print(\"target-data shapes:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(y_train.shape, y_val.shape, y_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "527d5290",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total vocabulary size plus 0 for unknown words\n",
    "embedding_vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"embedding_vocab_size: \", embedding_vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a3248ef",
   "metadata": {},
   "source": [
    "Checking why embedding vocab_size is 2 greater than original vocab size due to <empty> \n",
    "    #TODO: remove rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e71425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenizer word index into a set\n",
    "tokenizer_words = set(tokenizer.word_index.keys())\n",
    "\n",
    "# Convert the manual vocabulary into a set\n",
    "vocab_set = set(vocab)\n",
    "\n",
    "# Find the words in tokenizer but not in vocab\n",
    "tokenizer_only_words = tokenizer_words.difference(vocab_set)\n",
    "\n",
    "print(\"Words in tokenizer but not in vocab:\")\n",
    "print(tokenizer_only_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b891123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: gigaword or twitter?\n",
    "def load_embedding():\n",
    "    # Check if the pre-trained Word2Vec model is already downloaded\n",
    "    #w2v_pretrained_model = \"glove-twitter-100\"\n",
    "    w2v_pretrained_model = \"glove-wiki-gigaword-100\"\n",
    "    w2v_pretrained_model_filename = str(w2v_pretrained_model) + \"-word2vec.txt\"\n",
    "    if not os.path.exists(w2v_pretrained_model_filename):\n",
    "        print(\"\\nw2v model doesn't exist\")\n",
    "        # If the model does not exist, download it\n",
    "        model = api.load(\"glove-twitter-100\")\n",
    "        # Save the word2vec embeddings in the appropriate format\n",
    "        model.save_word2vec_format(w2v_pretrained_model_filename, binary=False)\n",
    "\n",
    "    # load embedding into memory, skip first line\n",
    "    print(\"Loading w2v model...\")\n",
    "    file = open(w2v_pretrained_model_filename, 'r', encoding='utf8')\n",
    "    lines = file.readlines()[1:]\n",
    "    file.close()\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2010e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_embedding = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(embedding, tokenizer):\n",
    "    # create a weight matrix for the Embedding layer from a loaded embedding\n",
    "\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((embedding_vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    count_all = 0\n",
    "    count_na = 0\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        # TODO: important note, pretrained word2vec model removes all neg_ and emojis (also other words) that are\n",
    "        #  not defined in the model it These values should prob? also be removed from the vocab (and update vocab size) to avoid mismatch in the embedding layer\n",
    "        if word in embedding.keys():\n",
    "            # print(embedding.get(word)[:3])\n",
    "            weight_matrix[i] = embedding.get(word)\n",
    "        else:\n",
    "            #print(word)\n",
    "            count_na += 1\n",
    "        count_all += 1\n",
    "    print(f'count_na/count_all: {str(count_na)}/{count_all}')\n",
    "    print(f\"embedding matrix shape: {weight_matrix.shape}\")\n",
    "\n",
    "    # save model in ASCII (word2vec) format\n",
    "    w2v_filename =  'processed/weight_matrix_word2vec.txt'\n",
    "    file_path = os.path.join(processed_folder_path, w2v_filename)\n",
    "    with open(w2v_filename, 'w') as file:\n",
    "        file.write('\\n'.join(' '.join(str(x) for x in row) for row in weight_matrix))\n",
    "    \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedding_vectors = get_weight_matrix(raw_embedding, tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fa517b2",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, LSTM, Dense, Conv1D, Dropout, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment labels to one-hot encoding\n",
    "num_classes = 3  # Number of sentiment classes [pos, neg, neut]\n",
    "y_train_encoded = np.zeros((len(y_train), num_classes))\n",
    "for i, label in enumerate(y_train):\n",
    "    y_train_encoded[i, label - 1] = 1\n",
    "\n",
    "y_val_encoded = np.zeros((len(y_val), num_classes))\n",
    "for i, label in enumerate(y_val):\n",
    "    y_val_encoded[i, label - 1] = 1\n",
    "\n",
    "y_test_encoded = np.zeros((len(y_test), num_classes))\n",
    "for i, label in enumerate(y_test):\n",
    "    y_test_encoded[i, label - 1] = 1\n",
    "\n",
    "    \n",
    "print(\"Check one-hot encoding:\\n\", y_train_encoded[:3])    \n",
    "print(\"\\ny-encoded Data Shape:\\n* train: {}\\n* validation: {}\\n* test: {}\\n\".format(y_train_encoded.shape, y_val_encoded.shape, y_test_encoded.shape))\n",
    "print(\"\\nx_train_encoded - type:\", type(x_train_encoded))\n",
    "print(\"y_train_encoded - type:\", type(y_train_encoded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0b1edcd",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4958c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: reorganize?\n",
    "# TODO: early stopping?\n",
    "# TODO: evaluation from the general functions\n",
    "# TODO: model architecture aspects (dropout) etc.\n",
    "# TODO: add train accuracy where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69975c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeefe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(score, model_name):\n",
    "    acc =  (score[1] * 100)\n",
    "    loss = score[0]\n",
    "    print(\"{} Accuracy: {}\".format(model_name, acc))\n",
    "    print(\"{} Loss: {}\".format(model_name, loss))\n",
    "    \n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(accuracy, loss, report, model_name):\n",
    "        # Save results\n",
    "    save_dir = f'results/{model_name}_results.txt'\n",
    "    with open(save_dir, 'w') as file:\n",
    "        file.write(f'{model_name} Accuracy: {accuracy}\\n')\n",
    "        file.write(f'{model_name} Loss: {loss}\\n')\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, x_test_encoded, y_test_encoded, y_test_true, params):\n",
    "    print(f'{model_name} Testing complete!\\n')\n",
    "    \n",
    "    score = model.evaluate(x_test_encoded, y_test_encoded, verbose=0)\n",
    "    # Calculate and save metrics\n",
    "    loss, accuracy = calculate_metrics(score, model_name)\n",
    "    \n",
    "    # Predict labels for the validation set\n",
    "    y_pred = model.predict(x_test_encoded)\n",
    "    # Convert one-hot encoded labels back to original format\n",
    "    y_pred = np.argmax(y_pred, axis=1)     \n",
    "    # Calculate classification report\n",
    "    report = calculate_classification_report(y_test_true, y_pred)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(accuracy, loss, report, model_name)\n",
    "\n",
    "    # Plot accuracy # TODO\n",
    "    #plot(history, model_name)\n",
    "\n",
    "    # Plot confusion matrix # TODO\n",
    "    senti_labels = ['negative', 'neutral', 'positive']\n",
    "    #plot_confusion_matrix(y_test, y_pred, senti_labels, model_name)\n",
    "    \n",
    "    print(\"Params: {}\\n\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(x_val_encoded, y_val_encoded, model, model_name, params):\n",
    "    score = model.evaluate(x_val_encoded, y_val_encoded, verbose=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    loss, accuracy = calculate_metrics(score, model_name)\n",
    "    print(\"Params: {}\\n\".format(params))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8fdb95a",
   "metadata": {},
   "source": [
    "### Single - Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the LSTM model\n",
    "def define_lstm_model(units, dropout_rate): #optimizer, learning_rate\n",
    "    single_lstm_model = Sequential()\n",
    "    single_lstm_model.add(Embedding(embedding_vocab_size, EMBEDDING_DIM, input_length=max_seq_length))\n",
    "    single_lstm_model.add(Dropout(dropout_rate))\n",
    "    single_lstm_model.add(LSTM(units=units))\n",
    "    single_lstm_model.add(Dense(3, activation='softmax'))\n",
    "    single_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return single_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set epochs and batch size\n",
    "single_lstm_model = KerasClassifier(build_fn=define_lstm_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46363d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "lstm_param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    #'optimizer': [Adam, SGD, RMSprop, Adagrad],\n",
    "    #'learning_rate': [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce49c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=single_lstm_model, param_grid=lstm_param_grid, cv=3)\n",
    "grid_search.fit(x_train_encoded, y_train_encoded)\n",
    "\n",
    "# Get the best parameters and best score from grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "\n",
    "# Get the mean test scores and standard deviations of test scores for all parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_results = results_df.sort_values(by='mean_test_score', ascending=False)\n",
    "top3_models = sorted_results[:5] # TODO: update 10 to 3\n",
    "print_top3_models(top3_models)\n",
    "top3_models = sorted_results[:3] # TODO: and delete this\n",
    "top3_params = top3_models['params'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d084baf",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c5e9303",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the top 3 models on the validation set\n",
    "# TODO: remove f1_score  \n",
    "# TODO: early stopping & batch_size?\n",
    "single_lstm_candidate_1 = define_lstm_model(units=top3_params[0]['units'], dropout_rate=top3_params[0]['dropout_rate'])\n",
    "single_lstm_candidate_1.fit(x_train_encoded, y_train_encoded, epochs=3)\n",
    "\n",
    "single_lstm_candidate_2 = define_lstm_model(units=top3_params[1]['units'], dropout_rate=top3_params[1]['dropout_rate'])\n",
    "single_lstm_candidate_2.fit(x_train_encoded, y_train_encoded, epochs=3)\n",
    "\n",
    "single_lstm_candidate_3 = define_lstm_model(units=top3_params[2]['units'], dropout_rate=top3_params[2]['dropout_rate'])\n",
    "single_lstm_candidate_3.fit(x_train_encoded, y_train_encoded, epochs=3)\n",
    "\n",
    "\n",
    "# TODO: after fixing plotting set boolean to include or exclude plotting etc.\n",
    "predict_data(x_val_encoded, y_val_encoded, single_lstm_candidate_1,  \"LSTM-single-1\", top3_params[0])\n",
    "predict_data(x_val_encoded, y_val_encoded, single_lstm_candidate_2, \"LSTM-single-2\", top3_params[1])\n",
    "predict_data(x_val_encoded, y_val_encoded, single_lstm_candidate_3, \"LSTM-single-3\", top3_params[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc6833b2",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best model and evaluate the models on the test data #TODO\n",
    "single_lstm_best = single_lstm_candidate_1\n",
    "evaluate_model(single_lstm_best,  \"LSTM-single-best\", x_test_encoded, y_test_encoded, y_test, top3_params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7ab0df6",
   "metadata": {},
   "source": [
    "### Multi - Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cfd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy-paste above to multi\n",
    "def define_multi_channel_lstm_model(units1, units2, dense_units):\n",
    "    # Vocabulary-based embedding layer\n",
    "    inputs1 = Input(shape=(max_seq_length,))\n",
    "    embedding1 = Embedding(embedding_vocab_size, EMBEDDING_DIM,\n",
    "                           input_length=max_seq_length)(inputs1)\n",
    "    lstm1 = LSTM(units=units1)(embedding1)\n",
    "\n",
    "    # Word2Vec embedding layer\n",
    "    inputs2 = Input(shape=(max_seq_length,))\n",
    "    embedding2 = Embedding(embedding_vocab_size, EMBEDDING_DIM,\n",
    "                           input_length=max_seq_length,\n",
    "                           weights=[w2v_embedding_vectors], trainable=False)(inputs2)\n",
    "    lstm2 = LSTM(units=units2)(embedding2)\n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    merged = concatenate([lstm1, lstm2])\n",
    "\n",
    "    # Dense layer for the merged inputs & Output Layer\n",
    "    merged_dense = Dense(units=dense_units, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='softmax')(merged_dense)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = KerasClassifier(build_fn=define_multi_channel_lstm_model, verbose=0)\n",
    "# multi_lstm_model = define_multi_channel_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "multi_lstm_param_grid = {\n",
    "    'units1': [64, 128],\n",
    "    'units2': [64, 128],\n",
    "    'dense_units': [32, 64],\n",
    "    #'batch_size': [16, 32],\n",
    "    #'epochs': [10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = product(*multi_lstm_param_grid.values())\n",
    "models = []\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(params)\n",
    "    units1, units2, dense_units = params\n",
    "    \n",
    "    multi_lstm_model = define_multi_channel_lstm_model(\n",
    "        units1=units1,\n",
    "        units2=units2,\n",
    "        dense_units=dense_units\n",
    "    )\n",
    "    \n",
    "    x_train = [x_train_encoded, x_train_encoded]\n",
    "    y_train = asarray(y_train_encoded)\n",
    "    \n",
    "    multi_lstm_model.fit(x_train, y_train)\n",
    "    loss, accuracy = multi_lstm_model.evaluate(x_train, y_train)\n",
    "    \n",
    "    accuracy = accuracy * 100\n",
    "    models.append({\n",
    "            'units1': units1,\n",
    "            'units2': units2,\n",
    "            'dense_units': dense_units,\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top3_models(top3_models):\n",
    "    print(\"\\nTop 3 parameter combinations ranked by performance (from best to worst):\")\n",
    "    for index, row in top3_models.iterrows():\n",
    "        units1 = row['units1']\n",
    "        units2 = row['units2']\n",
    "        dense_units = row['dense_units']\n",
    "        loss = row['loss']\n",
    "        accuracy = row['accuracy']\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}, Loss: {loss:.4f} for units1: {units1}, units2: {units2}, dense_units: {dense_units}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f03c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of models to a pandas DataFrame\n",
    "top3_models = pd.DataFrame(models)\n",
    "\n",
    "# Sort models based on accuracy in descending order and loss in ascending order\n",
    "top3_models = top3_models.sort_values(by=['accuracy', 'loss'], ascending=[False, False])\n",
    "\n",
    "top3_models = models[:5] # TODO: change 5 to 3\n",
    "top3_models = pd.DataFrame(top3_models)\n",
    "\n",
    "print_top3_models(top3_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14999c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in top3_models.iterrows():\n",
    "    units1 = int(row['units1'])\n",
    "    units2 = int(row['units2'])\n",
    "    dense_units = int(row['dense_units'])\n",
    "\n",
    "    multi_lstm_candidate_model = define_multi_channel_lstm_model(\n",
    "        units1=units1,\n",
    "        units2=units2,\n",
    "        dense_units=dense_units\n",
    "    )\n",
    "\n",
    "    x_train = [x_train_encoded, x_train_encoded]\n",
    "    y_train = asarray(y_train_encoded)\n",
    "\n",
    "    multi_lstm_candidate_model.fit(x_train, y_train)\n",
    "    # save the model\n",
    "    multi_lstm_model.save(f'multi-lstm-model-{index}.h5')\n",
    "\n",
    "    x_val = [x_val_encoded, x_val_encoded]\n",
    "    predict_data(x_val, y_val_encoded, multi_lstm_candidate_model,  f\"LSTM-multi-{index}\", top3_params[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4410f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# set index and load the model\n",
    "index = 0\n",
    "multi_lstm_best = load_model(f'multi-lstm-model-{index}.h5')\n",
    "x_test = [x_test_encoded, x_test_encoded]\n",
    "evaluate_model(multi_lstm_best,  \"LSTM-multi-best\", x_test, y_test_encoded, y_test, top3_params[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d38e720",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "658bc4eb",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bae840e2",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
